#pragma once

#include <vector>
#include <parallel/algorithm>
#include <parallel/numeric>
#include "utils/libs/boost_hash.hpp" //<boost/functional/hash.hpp>
#include <random>
#include <iostream>

#include "utils/load_balancing.hpp"
#include "utils/sort.hpp"
#include "utils/random.hpp"
#include "utils/memory.hpp"
#include "utils/vector.hpp"
#include "utils/complex.hpp"

// debug levels
#ifndef STEP_DEBUG_LEVEL
	#define STEP_DEBUG_LEVEL 1
#endif
#ifndef PRINT_DEBUG_LEVEL_1
	#define PRINT_DEBUG_LEVEL_1 0.5
#endif
#ifndef PRINT_DEBUG_LEVEL_2
	#define PRINT_DEBUG_LEVEL_2 1.5
#endif
#ifndef PRINT_DEBUG_LEVEL_3
	#define PRINT_DEBUG_LEVEL_3 2
#endif

#ifdef USE_HASHMAP
	#include <tbb/concurrent_hash_map.h> // For concurrent hash map.
	
	// proportion of the graph tested for collisions
	#ifndef COLLISION_TEST_PROPORTION
		#define COLLISION_TEST_PROPORTION 0.1
	#endif
	
	// minimum amount of collision for interaction
	#ifndef COLLISION_TOLERANCE
		#define COLLISION_TOLERANCE 0.05
	#endif
#endif

#ifdef USE_MPRF
	// default tolerance
	#ifndef TOLERANCE
		#define TOLERANCE 0
	#endif

	// import
	#include "utils/libs/mpreal.h"
	
	// namespace for math functions
	namespace precision = mpfr;

	// type
	#define PROBA_TYPE precision::mpreal

	// precision setter
	#define SET_PRECISION(precision_) PROBA_TYPE::set_default_prec(precision_);
#else
	// default tolerance
	#ifndef TOLERANCE
		#define TOLERANCE 1e-18
	#endif

	// standard type
	#define PROBA_TYPE long double

	// precision setter
	#define SET_PRECISION(precision)

	// namespace for math functions
	namespace precision = std;
#endif

/* default variables preprocessor definition:
	- "SAFETY_MARGIN" correpsponds to "safety_margin" (described in the definition of "get_max_num_graphs()").
	- "TOLERANCE" (default is different if MPFR is used or not) is the minimum probability a graph can have before being automaticly ignored.
	- "ITEARTION_DISCRIMINATION_FACTOR" is a factor discriminating the "previous iteration" against the "current iteration" when computing the max number of graphs.
	- "MEMORY_DISCRIMINATION_FACTOR" is a factor discriminating the impact of the amount of free memory against the one of iterations when computing the max number of graphs.
*/
#ifndef SAFETY_MARGIN
	#define SAFETY_MARGIN 0.2
#endif
	#ifndef ITEARTION_DISCRIMINATION_FACTOR
	#define ITEARTION_DISCRIMINATION_FACTOR 1.35
#endif
#ifndef MEMORY_DISCRIMINATION_FACTOR
	#define MEMORY_DISCRIMINATION_FACTOR 0.65
#endif

// global variable definition
PROBA_TYPE tolerance = TOLERANCE;
float safety_margin = SAFETY_MARGIN;
float iteartion_discrimination_factor = ITEARTION_DISCRIMINATION_FACTOR;
float memory_discrimination_factor = MEMORY_DISCRIMINATION_FACTOR;
float collision_test_proportion = COLLISION_TEST_PROPORTION;
float collision_tolerance = COLLISION_TOLERANCE;

/*
defining openmp function's return values if openmp isn't installed or loaded
*/ 
#ifndef _OPENMP
	#define omp_set_nested(i)
	#define omp_get_thread_num() 0
	#define omp_get_num_thread() 1
#endif

// type definition
typedef class state state_t;
typedef char op_type_t;

// debugging options
float verbose = 0;
int max_num_graph_print = 20;

/*
global header that can be used to define global variables from other files:
*/

#ifdef STATE_GLOBAL_HEADER
	STATE_GLOBAL_HEADER
#endif

/*
The "MID_STEP_FUNCTION(n)" function is called at the end of each step (inside a "omp single" region) with n between 0 (the first step) and the total number of step.
If not predefined, it will be defined as a debug function (that won't print for n=0).
It can be used to insert timming or debuging code in the step function:
*/

#ifndef MID_STEP_FUNCTION
	#define MID_STEP_FUNCTION(n)
#endif
#define MID_STEP_FUNCTION_WITH_DEBUG(n) \
	MID_STEP_FUNCTION(n) \
	if (n > 0 && verbose >= STEP_DEBUG_LEVEL) \
		std::cerr << "step "#n"\n";

/*
number of threads
*/

const size_t num_threads = []() {
	int num_threads;
	#pragma omp parallel
	#pragma omp single
	num_threads = omp_get_num_threads();

	return num_threads;
}();

/*
!!!!!
What are called "sub-nodes" are nodes containers that are used to point to other node container (to generate pairs, left or right nodes).

Iteration protocol is:
  - (1): use a rule to put all operation inside of the vector "operations".

  - (2): calculate the number of child graph generated by each parent graph and populate "num_childs" (*)

  - (3): compute a partial sum over "num_child" to (a) get the total number of symbolic graphs (b) know where the childs of each graphs begin and end.
  	read the total number of child graph generated by each parent graph and populate:
   "next_gid" (gid of the future graph), "parent_gid" (gid of the parent graph) and "child_id" (***) (the local id of the child among all its siblings).

  - (4, "symbolic iteartion"): by iterating over "next_gid" and using the rule, populate "next_hash", "next_real" and "next_imag" through a symbolic iteration (**),
  	and populate "symbolic_num_nodes" and "symbolic_num_sub_nodes" which are respectively the number of node and of sub-nodes for each new graph.

  - (5): We first sort graphs according to "next_hash" (*****).
  	We then sum the magnitude ("next_real" and "next_imag") of graph of equal hash.
  	We then partition the state so we only keep the graphs that accumulated the magnitude of graphs of equal hash.
	
  - (6): compute the average memory usage of a graph.
  	We can then compute "max_num_graphs" according to the value of "get_free_mem_size()" and a "safety_margin" (a proportion of memory which should be left free).
		We then keep "max_num_graphs" graphs, with each graph having a probability of being kept (hopefully) proportional to its probability (****).
			
  - (7): reserve all public vectors for the new iteration by iterating over the N first "next_gid" and using "parent_gid" and "child_id",
  	and assign "node_begin" and "sub_node_begin" by accumulating "symbolic_num_nodes" and "symbolic_num_sub_nodes".

  - (8): generate all new graphs of the new state by iterating over the N first "next_gid" and using "parent_gid" and "child_id".

  - (9): normalize the iteration, by first summing the total proba.
  	and then go over all graphs and divide their magnitude by the square root of the total probability.

  - (10): swap the previous iteration with the next iteration.

step (5) and (6) can be skiped for "fast iterations" and "probabilist iteration"

(*) to compute the number of child you just compute "pow(2, num_operations)"

(**) it's possible to compute the hash of a child graph without actually computing it for most rules

(***) The nth bit of "child\_id" corresponds to whether the nth operation should be executed or not.

(****) To keep n graph with a probability proportional to their own probability, we :
	- generate a random number for each graph, following an given distribution, for which the rate is the probability of the graph.
  - select the "max_num_graphs" graphs with the smallest previously mentioned "random number".
the optimal distribution found through experiments is "X_p = log( -log(U) / p )" (see ../../validation/)

(*****)

Load balancing:
	- steps (1), (2) and (4) have workloads of complexity proportional to the number of nodes of previous graphs,
		they are then balanced according to section of equal total number of nodes.

	- steps (3), (5), (6), (9) have constant workloads per graph, and are balanced with sections of equal number of graphs.

	- steps (8) has a workload complexity proportional to the number of nodes of future graphs,
		they are then balanced according to section of equal total number of nodes.
*/

/* random generator */
unfiorm random_generator;

class state {
public:
	// type definition of a node
	typedef enum node_type {
		left_t = -3, // ().l
		right_t, // ().r
		element_t, // (n)
		pair_t, // () v ()
	} node_type_t;

	/* 
	vectors can have 3 different sizes :
		- (a) the number of graph (so a single element per graph), and + 1
		- (b) the total number of nodes (sum of the number of nodes for each graph)
		- (c) the total number of sub-nodes
	*/

	/* 
	definition of the iteration struct:
		- stores vector describing an iteration
		- has member functions to resize sizes (a), (b), and (c)
		- has getters and setters for each properties
	*/

	/* total proba befor normalization */
	PROBA_TYPE total_proba = 1;

	typedef struct iteration {
		size_t num_graphs = 0;

		// graph magnitude
		numa_vector<PROBA_TYPE> real; /* of size (a) */
		numa_vector<PROBA_TYPE> imag; /* of size (a) */

		// begin for each size
		numa_vector<size_t> node_begin; /* of size (a + 1), refers to vector of size (b) */
		numa_vector<size_t> sub_node_begin; /* of size (a + 1), refers to vectors of size (c) */

		// node properties
		/* !!!
		can't use bool because bit vectors aren't thread safe
		!!! */
		numa_vector</*bool*/ char> left_; /* of size (b), correspond to the presence of a particule going left at a node */
		numa_vector</*bool*/ char> right_; /* of size (b), correspond to the presence of a particule going right at a node */
		numa_vector<unsigned short int> node_id_c; /* of size (b), points to the sunode_node (c) namming the ith node (b) */

		// sub node properties
		/*
		"left_idx__or_element__and_has_most_left_zero__or_is_trash_" stores:
			- either 0 to signify that the sub-node is trash and can be written over (since 0 can't be used for any other node since it is always positive)
			- or the index of another node (for .l or .r) + 1 (to be able to read the sign of a node with index 0)
			- or the integer naming an element + 1 (to be able to read the sign of an element of name 0)
		and "has_most_left_zero" (*) which is stored through the sign (less than 0 if true).

		"right_idx__or_type_" stores:
			- either the index of an other node (for pairs), which is greater than, or equal to zero
			- or the node type if the node is not a pair (which is strictly less then zero).

		(*) "has_most_left_zero" is an arbitrary lexicographic order to create a "reference rotation of graphs".
			The node which is the "most_left_zero" is the node countaining the name "0(.l)^n" with the greatest n.
		*/
		numa_vector<short int> left_idx__or_element__and_has_most_left_zero__or_is_trash_; /* of size (c) */
		numa_vector<short int> right_idx__or_type_; /* of size (c) */
		numa_vector<size_t> node_hash; /* of size (c) */

		/*
		intermediary vectors used to generate the next iteration :
		*/

		// vector of operations
		numa_vector<op_type_t> operations; /* of size (b) */

		// number of sub-graph for each parent
		numa_vector<size_t> num_childs; /* of size (a) + 1 */

		/* resize operators */
		// resize size (a)
		void resize_num_graphs(size_t size) {
			real.resize(size);
			imag.resize(size);
			node_begin.resize(size + 1);
			sub_node_begin.resize(size + 1);
			num_childs.resize(size + 1);
		}

		// resize size (b)
		void resize_num_nodes(size_t size) {
			left_.resize(size);
			right_.resize(size);
			node_id_c.resize(size);
			operations.zero_resize(size);
		}

		// resize size (c)
		void resize_num_sub_nodes(size_t size) {
			left_idx__or_element__and_has_most_left_zero__or_is_trash_.resize(size);
			right_idx__or_type_.resize(size);
			node_hash.resize(size);
		}

		/* hashers */
		/*
		this functions is used to compute hash values without generating nodes at the symbolic iteration 
			("by_value" means from node properties and not from node index, since the node doesn't exist in memory).
		*/
		size_t inline hash_node_by_value(size_t gid, short int left_idx__or_element__and_has_most_left_zero, short int right_idx__or_type) const {
			size_t hash_ = 0;
			size_t left_idx_or_element = std::abs(left_idx__or_element__and_has_most_left_zero) - 1; // left_idx_or_element from left_idx__or_element__and_has_most_left_zero

			if (right_idx__or_type == element_t) {
				hash_ = left_idx_or_element; // if element
			} else
				hash_ = hash(gid, left_idx_or_element); // else get the hash of the node of idx "left_idx_or_element"

			if (right_idx__or_type < pair_t) {
				boost::hash_combine(hash_, right_idx__or_type); // if not a pair, combine the hash with type
			} else
				boost::hash_combine(hash_, hash(gid, right_idx__or_type)); // else combine the hash with the hash of the other node of the pair.

			return hash_;
		}
		/*
		this function is used when generating graphs after the symbolic iteration
		*/
		void inline hash_node(size_t gid, unsigned short int node) {
			size_t id = sub_node_begin[gid] + node; // memory location
			node_hash[id] = hash_node_by_value(gid, left_idx__or_element__and_has_most_left_zero__or_is_trash_[id], right_idx__or_type_[id]); // assign hash to "hash_node_by_value(...)"
		}

		/* getters */
		// sizes
		size_t inline num_nodes(size_t gid) const { return node_begin[gid + 1] - node_begin[gid]; } // num_node is the distance between the begining and the end of its node
		size_t inline num_sub_node(size_t gid) const { return sub_node_begin[gid + 1] - sub_node_begin[gid]; } // num_sub_node is the distance between the begining and the end of its sub-node

		// getter for nodes
		unsigned short int inline node_id(size_t gid, unsigned short int node) const { return node_id_c[node_begin[gid] + node]; }
		bool inline left(size_t gid, unsigned short int node) const { return left_[node_begin[gid] + node]; }
		bool inline right(size_t gid, unsigned short int node) const { return right_[node_begin[gid] + node]; }
		op_type_t inline operation(size_t gid, unsigned short int node) const { return operations[node_begin[gid] + node]; }

		// raw getters for sub-nodes
		size_t hash(size_t gid, unsigned short int node) const { return node_hash[sub_node_begin[gid] + node]; }
		short int inline right_idx(size_t gid, unsigned short int node) const { return right_idx__or_type_[sub_node_begin[gid] + node]; }
		short int inline &right_idx(size_t gid, unsigned short int node) { return right_idx__or_type_[sub_node_begin[gid] + node]; }
		/*
		"raw_left_idx" corresponds directly to "left_idx__or_element__and_has_most_left_zero__or_is_trash_" without any computation (which has no meaning, hence "raw").
		"right_idx" doesn't have a "raw" counterpart since it has a meaning without any computation.
		*/
		short int inline raw_left_idx(size_t gid, unsigned short int node) const { return left_idx__or_element__and_has_most_left_zero__or_is_trash_[sub_node_begin[gid] + node]; }
		short int inline &raw_left_idx(size_t gid, unsigned short int node) { return left_idx__or_element__and_has_most_left_zero__or_is_trash_[sub_node_begin[gid] + node]; }
		
		// composits getters for raw_left_idx
		/*
		"left_idx" is equivalent to "raw_left_idx" without the sign and shifted index
		*/
		unsigned short int inline left_idx(size_t gid, unsigned short int node) const { 
			return std::abs(raw_left_idx(gid, node)) - 1; // absolute value minus one to get rid of the sign
		}
		unsigned short int inline element(size_t gid, unsigned short int node) const { return left_idx(gid, node); } // alias "to left_idx(...)"
		bool inline is_trash(size_t gid, unsigned short int node) const { return raw_left_idx(gid, node) == 0; }	// trash if left_idx__or_element__and_has_most_left_zero__or_is_trash_ is zero
		bool inline has_most_left_zero(size_t gid, unsigned short int node) const {
			return raw_left_idx(gid, node) < 0; // true if left_idx__or_element__and_has_most_left_zero__or_is_trash_ < 0
		}

		// composits getters for raw_right_idx
		node_type_t inline node_type(size_t gid, unsigned short int node) const {
			return std::min((node_type_t)right_idx(gid, node), pair_t); // pair if right_idx__or_type_ >= 0, otherwise the type is dorectly right_idx__or_type_
		}

		/* setters */
		// setters for nodes
		void inline set_node_id(size_t gid, unsigned short int node, unsigned short int value) { node_id_c[node_begin[gid] + node] = value; }
		void inline set_left(size_t gid, unsigned short int node, bool value) { left_[node_begin[gid] + node] = value; }
		void inline set_right(size_t gid, unsigned short int node, unsigned short int value) { right_[node_begin[gid] + node] = value; }
		void inline set_operation(size_t gid, unsigned short int node, op_type_t value) { operations[node_begin[gid] + node] = value; }

		// raw setters for sub-nodes
		void inline set_raw_left(size_t gid, unsigned short int node, short int value) { raw_left_idx(gid, node) = value; }
		
		// composite setters for raw_left_idx
		void inline set_is_trash(size_t gid, unsigned short int node) { set_raw_left(gid, node, 0); } // set to zero
		void inline set_left_idx(size_t gid, unsigned short int node, unsigned short int value) { set_raw_left(gid, node, value + 1); } // set value, including the index shift
		void inline set_element(size_t gid, unsigned short int node, unsigned short int value) { set_left_idx(gid, node, value); } // alias for "set_left_idx(...)"
		void inline set_has_most_left_zero(size_t gid, unsigned short int node, bool has_most_left_zero_) {
			short int &temp = raw_left_idx(gid, node);

			if (has_most_left_zero_ == (temp > 0)) // switch the sign if it doesn't correspond
				temp *= -1;
		}

		// composite setters for raw_right_idx
		void inline set_right_idx(size_t gid, unsigned short int node, unsigned short int value) { right_idx(gid, node) = value; }
		void inline set_type(size_t gid, unsigned short int node, node_type_t value) { right_idx(gid, node) = value; }
		
		/* randomize function */
		void randomize() {
			// random genearator
			size_t size = left_.size();
			for (int i = 0; i < size; ++i) {
				/* throw a coin to decide the presence of a particule going right or left on each node of each graph */
				left_[i] = std::rand() & 1;
				right_[i] = std::rand() & 1;
			}
		}
	} iteration_t;

	/* two iterations are stored in a state and are swaped at the end of each step */
	iteration_t current_iteration, next_iteration;

	/* constructor for multiple graphs of a given size */
	state(size_t size, size_t n) {
		current_iteration.num_graphs = n;

		// resize current_iteration
		current_iteration.resize_num_graphs(n);
		current_iteration.resize_num_nodes(size*n);
		current_iteration.resize_num_sub_nodes(size*n);

		// set intitial vector values
		current_iteration.real[0] = 1 / precision::sqrt((PROBA_TYPE)n);
		current_iteration.node_begin[0] = 0;
		current_iteration.sub_node_begin[0] = 0;

		// set the node type for all nodes
		std::fill(current_iteration.right_idx__or_type_.begin(),
			current_iteration.right_idx__or_type_.begin() + size*n,
			element_t);

		// fill graphs with empty nodes
		std::fill(current_iteration.left_.begin(),
			current_iteration.left_.begin() + size*n,
			false);
		std::fill(current_iteration.right_.begin(),
			current_iteration.right_.begin() + size*n,
			false);

		for (size_t gid = 0; gid < n; ++gid) {
			// set the magnitude each graphs
			current_iteration.real[gid] = current_iteration.real[0]; current_iteration.imag[gid] = 0;

			// giving "size" nodes and sub-nodes for the graph "gid" 
			current_iteration.node_begin[gid + 1] = current_iteration.node_begin[gid] + size;
			current_iteration.sub_node_begin[gid + 1] = current_iteration.sub_node_begin[gid] + size;

			// initiate the sub-node id of each node
			std::iota(current_iteration.node_id_c.begin() + current_iteration.node_begin[gid],
				current_iteration.node_id_c.begin() + current_iteration.node_begin[gid + 1],
				0);

			// intiate the name of each sub-node
			std::iota(current_iteration.left_idx__or_element__and_has_most_left_zero__or_is_trash_.begin() + current_iteration.node_begin[gid],
				current_iteration.left_idx__or_element__and_has_most_left_zero__or_is_trash_.begin() + current_iteration.node_begin[gid + 1],
				1);

			// set has_most_left_zero for the first node of each graph
			current_iteration.left_idx__or_element__and_has_most_left_zero__or_is_trash_[current_iteration.node_begin[gid]] = -1;

			// hash each node
			for (size_t node = 0; node < size; ++node)
				current_iteration.hash_node(gid, node);
		}
	}

	/* vector for work sharing */
	std::vector<size_t> work_sharing_begin = std::vector<size_t>(num_threads + 1);
#ifdef USE_HASHMAP
	tbb::concurrent_hash_map<size_t, size_t> elimination_map;
#else
#ifndef USE_QUICK_SORT
	numa_vector<size_t> next_gid_buffer;
#endif
#endif

	/* constructor for a single graph of a given size */
	state(size_t size) : state(size, 1) {}

	/* randomize function */
	void randomize() { current_iteration.randomize(); }

	/* 
	symbolic iteration: 
		- vectors for temporary properties stored at the symbolic iteration
		- member function to resize the number of graph at symbolic iteration
	*/

	// number of graphs
	size_t symbolic_num_graphs = 0;
	size_t symbolic_num_graphs_after_interferences = 0;

	// new graphs
	/*
	"is_last_index[gid]" is true if the graph "gid" is the graph which will accumulate the magnitude of the graphs of equal hash
	*/
	numa_vector</*bool*/ char> is_last_index; /* of size (a) for the symbolic iteration */
	numa_vector<size_t> next_gid; /* of size (a) for the symbolic iteration */
	numa_vector<size_t> parent_gid; /* of size (a) for the symbolic iteration */
	numa_vector<unsigned short int> child_id; /* of size (a) for the symbolic iteration */

	// new graph hash
	numa_vector<size_t> next_hash; /* of size (a) for the symbolic iteration */

	// new graph random selector
	numa_vector<double> random_selector; /* of size (a) for the symbolic iteration */

	// new graph magnitude
	numa_vector<PROBA_TYPE> next_real; /* of size (a) for the symbolic iteration */
	numa_vector<PROBA_TYPE> next_imag; /* of size (a) for the symbolic iteration */

	// size for each size
	numa_vector<size_t> symbolic_num_nodes; /* of size (a + 1), refers to vector of size (b) */
	numa_vector<size_t> symbolic_num_sub_nodes; /* of size (a + 1), refers to vectors of size (c) */

	// resize operator
	void resize_symbolic_num_graphs(size_t size) {
		next_gid.iota_resize(size);
#if !defined(USE_HASHMAP) && !defined(USE_QUICK_SORT)
		next_gid_buffer.zero_resize(size);
#endif

		parent_gid.zero_resize(size);
		child_id.zero_resize(size);
		is_last_index.zero_resize(size);
		next_hash.zero_resize(size);
		next_real.zero_resize(size);
		next_imag.zero_resize(size);
		symbolic_num_nodes.zero_resize(size);
		symbolic_num_sub_nodes.zero_resize(size);
		random_selector.zero_resize(size);
	}

/* 
rule virtual class definition:
	- A rule can be "probabilist" or "quantum".
	- For each rule, the "none" operation has to be represented by 0
	- It has virtual member functions that needs to be overloaded by each individual rule.

Non-virtual member functions are:
	- Constructor (for both probabilist and quantum rules).
	- "multiply_proba(PROBA_TYPE &real, PROBA_TYPE &imag, op_type_t op, bool do_)" to multiply a magnitude by the rule's matrix (according to the operation type).
	- "num_childs()" which is used at step 2 of the iteration.
	- "do_operation(unsigned short int &child_id)" that check if some operation should be done or not according to the "child_id", and the type of rule.
	- "write_operation(op_type_t op)" which apply the probabilist decision if the rule is probabilist, else returns op.
*/
	typedef class rule {
	public:
		/* flag to determine the type of rule */
		bool probabilist = false;
		bool classical = false;
		bool identity = false;

		/* parameters of a stochiastic matrix */
		PROBA_TYPE p = 1; // probability of the first operation
		PROBA_TYPE q = 1; // probability of the second operation

		/* parameters of a unitary matrix */
		PROBA_TYPE do_real = 1; // non-diagonal terms
		PROBA_TYPE do_imag = 0;
		PROBA_TYPE do_not_real = 0; // diagonal terms
		PROBA_TYPE do_not_imag = 0;

		/* parameters for print */
		PROBA_TYPE theta, phi, xi;
		std::string name = "";
		bool move = true; // wether to move or not after each application of the rule
		size_t n_iter = 0; // number of application of the rule for each step

		/* constructors */
		// constructors for a unitary matrix
		rule(PROBA_TYPE theta_, PROBA_TYPE phi_, PROBA_TYPE xi_) : theta(theta_), phi(phi_), xi(xi_) {
			do_real = precision::sin(theta)* precision::cos(phi);
			do_imag = precision::sin(theta)* precision::sin(phi);
			do_not_real = precision::cos(theta)* precision::cos(xi);
			do_not_imag = precision::cos(theta)* precision::sin(xi);

			// check for identity
			identity = precision::abs(do_real) <= tolerance && precision::abs(do_imag) <= tolerance;

			// check for classical rule
			classical = precision::abs(do_not_real) <= tolerance && precision::abs(do_not_imag) <= tolerance;
		}

		// probabilist constructor (p != q)
		rule(PROBA_TYPE p_, PROBA_TYPE q_) : p(p_), q(q_), probabilist(true) {
			do_real = precision::sqrt(p);
			do_imag = precision::sqrt(q);
			do_not_real = precision::sqrt(1 - p);
			do_not_imag = precision::sqrt(1 - q);
		}

		// probabilist constructor (p == q)
		rule(PROBA_TYPE p_) : rule(p_, p_) {}

		// empty constructor
		rule() {}

		/* multiply the magnitude of a graph according to the operation and the rule */
		void inline multiply_proba(PROBA_TYPE &real, PROBA_TYPE &imag, op_type_t op /* either 0 or 1 */, bool do_) const {
			if (!probabilist) {

				/* quantum case */
				PROBA_TYPE sign = op ? 1 : -1;
				if (do_) {
					time_equal(real, imag, do_real, sign*do_imag);
				} else
					time_equal(real, imag, sign*do_not_real, do_not_imag);

				/* 
				representation of the unitary matrix:
				(	  do_not_real + i*do_not_imag	,			do_real + i*do_imag				)
				(   	do_real - i*do_imag 			,	-do_not_real + i*do_not_imag	)
				*/
			}
		}

		/* 
		probabilist:
			- randomly chooses whether to do operation or not according to p and q
		classical / quantum:
			- always write the operation
		*/
		op_type_t inline write_operation(op_type_t op) const {
			if (!probabilist || op == 0)
				return op;
			
			/* generate random number */
			if (random_generator() < (op == 1 ? p : q))
				return op;

			return 0; 
		}

		/*
		quantum:
			- check whether to do an operation or not (return the n_th bit of child_id)
		classical / probabilist:
			- always do the operation
		*/
		bool inline do_operation(unsigned short int &child_id) const {
			/* check if the rule is classical */
			if (probabilist || classical)
				return true;

			/* check if the rule is the identity */
			if (identity)
				return false;

			/* return the first bit and bit shift, effectivly returning the n_th bit */
			bool do_ = child_id & 1;
			child_id >>= 1;

			return do_;
		}

		/* step (1) */
		// virtual function to be overloaded
		virtual op_type_t operation(iteration_t const &s, size_t gid, unsigned short int node) const { return '\0'; }

		/* step (2) */
		/*
		probabilist / classical:
			- return 1 (since there is only one child)
		quantum:
			- count the number of operations in the graph (n), and returns 2^n (since each operation can be done or not independantly)
		*/
		unsigned short int num_childs(iteration_t const &s, size_t gid) const {
			/* check for "classical case" */
			if (probabilist || classical || identity)
				return 1;

			/* count operations */
			size_t num_op = 0;
			size_t num_nodes_ = s.num_nodes(gid);
			for (size_t node = 0; node < num_nodes_; ++node)
				num_op += s.operation(gid, node) != 0; // 0 is the "none" operation for all dynamics

			/* 2^n_op childs */
			return 1 << num_op;
		}

		/* step (4) */
		/* symbolic iteration */
		// virtual function to be overloaded
		virtual void child_properties(size_t& hash_,
			PROBA_TYPE& real, PROBA_TYPE& imag,
			size_t& num_nodes, size_t& num_sub_node,
			iteration_t const &s, size_t parent_id, unsigned short int child_id) const {}

		/* step (8) */
		/* generating actual graphs */
		// virtual function to be overloaded
		virtual void populate_new_graph(iteration_t const &s, iteration_t &next_iteration, size_t next_gid, size_t parent_id, unsigned short int child_id) const {}
	} rule_t;


	/* compute the maximum number of graph that can fit in memory accross two iterations */
	long long int inline get_max_num_graphs() const {
		// get the free memory and the total amount of memory...
		auto [total_memory, free_mem] = get_mem_usage_and_free_mem();

		// and according to the "safety_margin" (a proportion of total memory) compute the total delta between the amount free memory and the target
		long int mem_difference = free_mem - total_memory*safety_margin;

		// constant mem usage per vector elements for each size
		static const long long int graph_mem_usage = 2*sizeof(PROBA_TYPE) + 3*sizeof(size_t);
		static const long long int node_mem_usage = 2*sizeof(char) + sizeof(unsigned short int) + sizeof(op_type_t);
		static const long long int sub_node_mem_usage = 2*sizeof(short int) + sizeof(size_t);
		static const long long int symbolic_mem_usage = sizeof(char) + 3*sizeof(size_t) + sizeof(unsigned short int) + sizeof(size_t) + 2*sizeof(PROBA_TYPE) + sizeof(double)
#ifdef USE_QUICK_SORT
		- sizeof(size_t)
#endif
#ifdef USE_HASHMAP
		+ sizeof(size_t)
#endif
;

		long long int mem_usage_per_graph = (graph_mem_usage + // usage for a single graph
			(node_mem_usage * current_iteration.node_begin[current_iteration.num_graphs] + // usage for a node * total number of nodes
			sub_node_mem_usage * current_iteration.sub_node_begin[current_iteration.num_graphs] + // usage for a sub-node * total number of sub-nodes
			symbolic_mem_usage * symbolic_num_graphs / 2) // usage for a graph at the symbolic iteration  * total number of graphs at the symbolic iteration, divided by two since two iteration coexists
			/ current_iteration.num_graphs // divided by the number of graphs at the last step to obtain per-graph memory usage
			) * upsize_policy; // time the "upsize_policy" since it adds an memory inneficiency

		// ponderation of different factor :
		static const float next_it_ng_factor = 2 - iteartion_discrimination_factor;

		// get the total number of graphs that can fit in memory,
		// by adding the number of graphs that can fit in the "mem_difference" to the number of graphs in both iterations
		// then divided it by two since we need to have two iteartions at the same time.
		long long int max_num_graph = (next_iteration.num_graphs*next_it_ng_factor + 
			current_iteration.num_graphs*iteartion_discrimination_factor +
			mem_difference/mem_usage_per_graph*memory_discrimination_factor) / 2;

		if (max_num_graph <= 0)
			max_num_graph = min_vector_size;

		return std::max(max_num_graph, (long long int)min_vector_size);
	}

	/* step function */
	void inline step(rule_t const &rule, long int max_num_graphs) { step(rule, max_num_graphs, false, false); }
	void inline fast_step(rule_t const &rule) { step(rule, 0, true, true); }
	void step(rule_t const &rule, long long int max_num_graphs = -1, bool overwrite_max_num_graphs = true, bool fast = false) {
		/* check for calssical cases */
		if (rule.identity)
			return;

		/* allow nested parallism for __gnu_parallel inside omp single */
		omp_set_nested(3);

		total_proba = 0;

		MID_STEP_FUNCTION_WITH_DEBUG(0)

		/* !!!!!!!!!!!!!!!!
		NOTE:
			- current_num_nodes = current_iteration.node_begin[current_iteration.num_graphs]
			- next_num_nodes = next_iteration.node_begin[next_iteration.num_graphs]

		step (1) 
		
		reads: 2*current_iteration.num_graphs*sizeof(size_t) + n(rule)*current_num_nodes
		writes: current_num_nodes

		 !!!!!!!!!!!!!!!! */

		/* load sharing according to number of nodes */
		load_balancing_from_prefix_sum(current_iteration.node_begin.begin() + 1,
			current_iteration.node_begin.begin() + current_iteration.num_graphs + 1,
			work_sharing_begin.begin(), work_sharing_begin.end());

		#pragma omp parallel
		{
			size_t thread_id = omp_get_thread_num();

			/* get operations for each node of each graph */
			for (size_t gid = work_sharing_begin[thread_id]; gid < work_sharing_begin[thread_id + 1]; ++gid) {
				auto num_nodes_ = current_iteration.num_nodes(gid); /* 2 size_t reads per loop */

				/* get operations for each nodes of each graph */
				for (size_t node = 0; node < num_nodes_; ++node)
					current_iteration.set_operation(gid, node, rule.operation(current_iteration, gid, node)); /* n(rule) char reads, 1 char write per node */
			}

			#pragma omp barrier

			#pragma omp single
			{
				MID_STEP_FUNCTION_WITH_DEBUG(1)
			}

			/* !!!!!!!!!!!!!!!!
			step (2)

			reads: 2*current_iteration.num_graphs*sizeof(size_t) + current_num_nodes
			writes: current_iteration.num_graphs*sizeof(size_t)

			 !!!!!!!!!!!!!!!! */

			/* get the number of child for each graph */
			for (size_t gid = work_sharing_begin[thread_id]; gid < work_sharing_begin[thread_id + 1]; ++gid)
				current_iteration.num_childs[gid + 1] = rule.num_childs(current_iteration, gid); /* 2 size_t reads and 1 size_t write per loop, 1 char read per node */

			#pragma omp barrier

			#pragma omp single
			{
				MID_STEP_FUNCTION_WITH_DEBUG(2)

				/* !!!!!!!!!!!!!!!!
				step (3)

				reads: 2*current_iteration.num_graphs*sizeof(size_t)
				writes: symbolic_num_graphs*(sizeof(size_t) + sizeof(unsigned short int)) + 2*current_iteration.num_graphs*sizeof(size_t)

				 !!!!!!!!!!!!!!!! */

				/* partial sum of number of graph */
				current_iteration.num_childs[0] = 0;

				__gnu_parallel::partial_sum(current_iteration.num_childs.begin() + 1,
					current_iteration.num_childs.begin() + current_iteration.num_graphs + 1,
					current_iteration.num_childs.begin() + 1); /* 2 (1 in sequential but 2 in parallel) size_t reads and writes per loop (for current_iteration.num_graphs loops) */
				symbolic_num_graphs = current_iteration.num_childs[current_iteration.num_graphs];

				/* resize variables with the right_ number of elements */
				resize_symbolic_num_graphs(symbolic_num_graphs);
			}

			for (size_t gid = work_sharing_begin[thread_id]; gid < work_sharing_begin[thread_id + 1]; ++gid) {
				/* assign parent ids and child ids for each child */
				std::fill(parent_gid.begin() + current_iteration.num_childs[gid],
					parent_gid.begin() + current_iteration.num_childs[gid + 1],
					gid); /* 1 size_t write per symbolic graph */ 
				std::iota(child_id.begin() + current_iteration.num_childs[gid],
					child_id.begin() + current_iteration.num_childs[gid + 1],
					0);  /* 1 unsigned short int write per symbolic graph */ 
			}

			#pragma omp barrier

			#pragma omp single
			{
				MID_STEP_FUNCTION_WITH_DEBUG(3)
			}

			/* !!!!!!!!!!!!!!!!
			step (4)

			reads: symbolic_num_graphs*(6*sizeof(size_t) + 2*sizeof(PROBA_TYPE) + sizeof(short)) + 2*next_num_nodes
			writes: symbolic_num_graphs*(3*sizeof(size_t) + 2*sizeof(PROBA_TYPE))

			 !!!!!!!!!!!!!!!! */

			/* symbolic iteration :
				compute properties of each possible future graph */ 
			#pragma omp for schedule(static)
			for (size_t gid = 0; gid < symbolic_num_graphs; ++gid)
				rule.child_properties(next_hash[gid], /* 2 + 2*2 (sizes) size_t reads and 3 size_t write per symbolic graph */
					next_real[gid], next_imag[gid], /* 2 PROBA_TYPE reads and writes per symbolic graph */ 
					symbolic_num_nodes[gid], symbolic_num_sub_nodes[gid], /* 1 unsigned short int read per symbolic graph */
					current_iteration, parent_gid[gid], child_id[gid]); /* ~2 char reads per node of child */

			#pragma omp single
			{
				MID_STEP_FUNCTION_WITH_DEBUG(4)
			}

			/* !!!!!!!!!!!!!!!!
			step (5)

			reads: symbolic_num_graphs*(sizeof(size_t)*32 + sizeof(PROBA_TYPE)*4 + 10)
			writes: symbolic_num_graphs*(sizeof(size_t)*17 + sizeof(PROBA_TYPE)*2 + 1)

			 !!!!!!!!!!!!!!!! */

			/* no need to compute interference if we are in the probabilist case */
			if (!rule.probabilist) {
#ifdef USE_HASHMAP
				#pragma omp barrier

				size_t test_size = symbolic_num_graphs >= min_vector_size ? symbolic_num_graphs*collision_test_proportion : 0;

				if (!fast && test_size > 0) {
					#pragma omp for schedule(static)
					for (unsigned int gid = 0; gid < test_size; ++gid) { //size_t gid = next_gid[i];
						size_t hash = next_hash[gid];

						/* accessing key */
						tbb::concurrent_hash_map<size_t, size_t>::accessor it;
						if (elimination_map.insert(it, hash)) {
							/* if it doesn't exist add it */
							it->second = gid;

							/* keep this graph */
							is_last_index[gid] = true;
						} else {
							/* if it exist add the probabilities */
							next_real[it->second] += next_real[gid];
							next_imag[it->second] += next_imag[gid];

							/* discard this graph */
							is_last_index[gid] = false;
						}
						it.release();
					}

					/* check if we should continue */
					fast = test_size - elimination_map.size() > test_size*collision_test_proportion;
				}

				#pragma omp barrier

				if (!fast)
					#pragma omp for schedule(static)
					for (unsigned int gid = test_size; gid < symbolic_num_graphs; ++gid) { //size_t gid = next_gid[i];
						size_t hash = next_hash[gid];

						/* accessing key */
						tbb::concurrent_hash_map<size_t, size_t>::accessor it;
						if (elimination_map.insert(it, hash)) {
							/* if it doesn't exist add it */
							it->second = gid;

							/* keep this graph */
							is_last_index[gid] = true;
						} else {
							/* if it exist add the probabilities */
							next_real[it->second] += next_real[gid];
							next_imag[it->second] += next_imag[gid];

							/* discard this graph */
							is_last_index[gid] = false;
						}
						it.release();
					}

				#pragma omp single
				{
					elimination_map.clear();
#else
				if (!fast) {
#ifdef USE_QUICK_SORT
					#pragma omp single
					{
						/* sort according to hashes */
						__gnu_parallel::sort(next_gid.begin(), next_gid.begin() + symbolic_num_graphs,
								[&](long unsigned int gid1, long unsigned int gid2){
									return next_hash[gid1] < next_hash[gid2];
								});

						/* set is_last_index of the last graph */
						is_last_index[next_gid[symbolic_num_graphs - 1]] = true;
						work_sharing_begin[num_threads] = symbolic_num_graphs;
					}

					/* compute is_last_index */
					#pragma omp for
					for (size_t gid = 0; gid < symbolic_num_graphs - 1; ++gid)
						is_last_index[next_gid[gid]] = next_hash[next_gid[gid]] != next_hash[next_gid[gid + 1]]; /* 1 char write and 4 size_t reads per symbolic graph */

					work_sharing_begin[thread_id] = (thread_id * symbolic_num_graphs) / num_threads;
					if (work_sharing_begin[thread_id] != 0)
						while (!is_last_index[next_gid[work_sharing_begin[thread_id] - 1]])
							++work_sharing_begin[thread_id];

					#pragma omp barrier

					if (work_sharing_begin[thread_id] < work_sharing_begin[thread_id + 1]) {
#else
					#pragma omp single
					{
						/* share work according to hash */
						size_t count[256] = {0};
						parallel_radix_count_indexed_0(next_gid.begin(), next_gid.begin() + symbolic_num_graphs, /* 1 size_t write and 1 (index) + 2 size_t and 1 char reads per symbolic graph */
							next_hash.begin(),	/* + 1 size_t read and 1 size_t write per symbolic graphs */
							count);

						/* share work according to count */
						indexed_load_balancing_from_prefix_sum(count, count + 256, work_sharing_begin.begin(), work_sharing_begin.end());

						/* finish radix sort */
						radix_secon_loop_indexed_offset(next_gid.begin(), next_gid_buffer.begin(),
							symbolic_num_graphs,
							(unsigned char*)next_hash.begin(),
							count,
							7);
					}
				
					if (work_sharing_begin[thread_id] < work_sharing_begin[thread_id + 1]) {
						/* sort all graphs */
						radix_indexed_sort_1_7(next_gid_buffer.begin() + work_sharing_begin[thread_id], /* 7 size_t write and 1 (index) + 7*2 size_t and 7 char reads per symbolic graph */
							next_gid_buffer.begin() + work_sharing_begin[thread_id + 1], /* + 7 size_t read and 7 size_t write per symbolic graphs */
							next_gid.begin() + work_sharing_begin[thread_id],
							next_hash.begin());
						
						/* set is_last_index of the last graph */
						is_last_index[next_gid[work_sharing_begin[thread_id + 1] - 1]] = true;

						/* compute is_last_index */
						for (size_t gid = work_sharing_begin[thread_id]; gid < work_sharing_begin[thread_id + 1] - 1; ++gid)
							is_last_index[next_gid[gid]] = next_hash[next_gid[gid]] != next_hash[next_gid[gid + 1]]; /* 1 char write and 4 size_t reads per symbolic graph */
#endif
						/* partial sum over the interval since we know it starts and end at unique graphs */
						PROBA_TYPE sign;
						size_t last_id = next_gid[work_sharing_begin[thread_id]];
						for (size_t gid = work_sharing_begin[thread_id] + 1; gid < work_sharing_begin[thread_id + 1]; ++gid) {
							size_t id = next_gid[gid]; /* 1 size_t read per symbolic graphs */
							sign = !is_last_index[last_id]; /* 1 char read per symbolic graph */

							/* add probabilites of graph with equal hashes */
							next_real[id] += sign*next_real[last_id]; /* 2 PROBA_TYPE reads and 2 PROBA_TYPE writes per symbolic graph */
							next_imag[id] += sign*next_imag[last_id];

							last_id = id;
						}
					}	
				}

				#pragma omp barrier

				#pragma omp single
				{
#endif
					auto partitioned_it = next_gid.begin() + symbolic_num_graphs;
					if (!fast)
						/* get all unique graphs with a non zero probability */
						partitioned_it = __gnu_parallel::partition(next_gid.begin(), partitioned_it, /* 1 size_t read and 1 size_t write per symbolic graph */
						[&](size_t const &gid) {
							/* check if graph is unique */
							if (!is_last_index[gid]) /* 1 char read per symbolic graph */
								return false;

							/* check for zero probability */
							PROBA_TYPE r = next_real[gid]; /* 2 PROBA_TYPE reads per symbolic graph */
							PROBA_TYPE i = next_imag[gid];

							return r*r + i*i > tolerance; 
						});

					symbolic_num_graphs_after_interferences = std::distance(next_gid.begin(), partitioned_it);
					
					MID_STEP_FUNCTION_WITH_DEBUG(5)

					/* !!!!!!!!!!!!!!!!
					step (6)

					reads: symbolic_num_graphs_after_interferences*(2*sizeof(PROBA_TYPE) + 2*sizeof(float) + sizeof(size_t))
					writes: max_num_graphs*sizeof(size_t) + symbolic_num_graphs_after_interferences*sizeof(float)

					 !!!!!!!!!!!!!!!! */

					if (overwrite_max_num_graphs)
						max_num_graphs = get_max_num_graphs();

					if (max_num_graphs > 0 && symbolic_num_graphs_after_interferences > max_num_graphs) {

						/* generate random selectors */
						#pragma omp parallel for schedule(static)
						for (auto gid_it = next_gid.begin(); gid_it != partitioned_it; ++gid_it)  {
							PROBA_TYPE r = next_real[*gid_it]; /* 2 PROBA_TYPE reads per symbolic_num_graphs_after_interferences */
							PROBA_TYPE i = next_imag[*gid_it];

							double random_number = unfiorm_from_hash(next_hash[*gid_it]); //random_generator();
							random_selector[*gid_it] = precision::log( -precision::log(1 - unfiorm_from_hash(next_hash[*gid_it])) / (r*r + i*i)); /* 1 float write per symbolic_num_graphs_after_interferences */
						}

						/* select graphs according to random selectors */
						__gnu_parallel::nth_element(next_gid.begin(), next_gid.begin() + max_num_graphs, partitioned_it, /* 1 size_t read per symbolic_num_graphs_after_interferences */
						[&](size_t const &gid1, size_t const &gid2) { /* 1 size_t write per max_num_graphs */
							return random_selector[gid1] < random_selector[gid2]; /* 2 float reads per symbolic_num_graphs_after_interferences */
						});

						next_iteration.num_graphs = max_num_graphs;
					} else
						next_iteration.num_graphs = symbolic_num_graphs_after_interferences;

					MID_STEP_FUNCTION_WITH_DEBUG(6)

					/* !!!!!!!!!!!!!!!!
					step (7)

					reads: next_iteration.num_graphs*((6 + std::log2(next_iteration.num_graphs)*sizeof(size_t) + 2*sizeof(PROBA_TYPE))
					writes: next_iteration.num_graphs*((6 + std::log2(next_iteration.num_graphs)*sizeof(size_t) + 2*sizeof(PROBA_TYPE))

					 !!!!!!!!!!!!!!!! */

					/* sort to make memory access more continuous */
					__gnu_parallel::sort(next_gid.begin(), next_gid.begin() + next_iteration.num_graphs); /* 1 size_t read and write per next_iteration.num_graphs*log2(next_iteration.num_graphs) 

					/* resize new step variables */
					next_iteration.resize_num_graphs(next_iteration.num_graphs);
				}
			} else
				#pragma omp single
				{
					MID_STEP_FUNCTION_WITH_DEBUG(5)
					MID_STEP_FUNCTION_WITH_DEBUG(6)

					/* same number of graphs for a probabilist simulation */
					symbolic_num_graphs_after_interferences = symbolic_num_graphs;
					next_iteration.num_graphs = symbolic_num_graphs;
					next_iteration.resize_num_graphs(next_iteration.num_graphs);
				}

			/* prepare for partial sum */
			#pragma omp for schedule(static)
			for (size_t gid = 0; gid < next_iteration.num_graphs; ++gid) {
				size_t id = next_gid[gid];

				next_iteration.node_begin[gid + 1] = symbolic_num_nodes[id]; /* 1 size_t read and write per next_iteration.num_graphs */
				next_iteration.sub_node_begin[gid + 1] = symbolic_num_sub_nodes[id]; /* 1 size_t read and write per next_iteration.num_graphs */

				/* assign magnitude */
				next_iteration.real[gid] = next_real[id]; /* 2 PROBA_TYPE read and write per next_iteration.num_graphs */
				next_iteration.imag[gid] = next_imag[id];
			}

			#pragma omp single
			{
				/* compute the partial sums to get new node_begin and sub_node_begin */
				next_iteration.node_begin[0] = 0;
				__gnu_parallel::partial_sum(next_iteration.node_begin.begin() + 1, /* 2 size_t read and write per next_iteration.num_graphs */
					next_iteration.node_begin.begin() + next_iteration.num_graphs + 1,
					next_iteration.node_begin.begin() + 1);

				next_iteration.sub_node_begin[0] = 0;
				__gnu_parallel::partial_sum(next_iteration.sub_node_begin.begin() + 1, /* 2 size_t read and write per next_iteration.num_graphs */
					next_iteration.sub_node_begin.begin() + next_iteration.num_graphs + 1, 
					next_iteration.sub_node_begin.begin() + 1);

				/* resize new step variables */
				next_iteration.resize_num_nodes(next_iteration.node_begin[next_iteration.num_graphs]);
				next_iteration.resize_num_sub_nodes(next_iteration.sub_node_begin[next_iteration.num_graphs]);

				MID_STEP_FUNCTION_WITH_DEBUG(7)

				/* !!!!!!!!!!!!!!!!
				step (8)

				reads: n(rule)*next_iteration.num_graphs + 3*next_iteration.num_graphs
				writes: 2*next_iteration.num_graphs

				 !!!!!!!!!!!!!!!! */

				/* load sharing according to number of nodes */
				load_balancing_from_prefix_sum(next_iteration.node_begin.begin() + 1,
					next_iteration.node_begin.begin() + next_iteration.num_graphs + 1,
					work_sharing_begin.begin(), work_sharing_begin.end());
			}

			for (size_t gid = work_sharing_begin[thread_id]; gid < work_sharing_begin[thread_id + 1]; ++gid) {
				auto id = next_gid[gid]; /* 1 size_t read per next_iteration.num_graphs */
				/* populate graphs */
				rule.populate_new_graph(current_iteration, next_iteration, /* 2 char writes per next_num_nodes */
					gid, /* ~n_rule char reads per next_num_nodes */
					parent_gid[id], child_id[id]); /* 2 size_t read per next_iteration.num_graphs */
			}

			#pragma omp barrier

			#pragma omp single
			{
				MID_STEP_FUNCTION_WITH_DEBUG(8)
			}

			/* !!!!!!!!!!!!!!!!
			step (9)

			reads: 2*next_iteration.num_graphs*sizeof(PROBA_TYPE)
			writes: 2*next_iteration.num_graphs*sizeof(PROBA_TYPE)

			 !!!!!!!!!!!!!!!! */
			
			#ifdef USE_MPRF
				#pragma omp single
			#else
				#pragma omp for schedule(static) reduction(+ : total_proba)
			#endif
			for (size_t gid = 0; gid < next_iteration.num_graphs; ++gid) {
				/* compute total proba */
				PROBA_TYPE r = next_iteration.real[gid]; /* 2 PROBA_TYPE reads per next_iteration.num_graphs */
				PROBA_TYPE i = next_iteration.imag[gid];

				total_proba += r*r + i*i;
			}

			#pragma omp single
			total_proba = precision::sqrt(total_proba);
			
			/* normalize by divinding magnitudes by the square root of the total probability */
			#pragma omp for schedule(static)
			for (size_t gid = 0; gid < next_iteration.num_graphs; ++gid) {
				next_iteration.real[gid] /= total_proba;  /* 2 PROBA_TYPE writes per next_iteration.num_graphs */
				next_iteration.imag[gid] /= total_proba;
			}

			#pragma omp single
			total_proba *= total_proba;
		}

		MID_STEP_FUNCTION_WITH_DEBUG(9)

		/* !!!!!!!!!!!!!!!!
		step (10) 
		 !!!!!!!!!!!!!!!! */

		/* swap states */
		std::swap(current_iteration, next_iteration);
	}
};


/*
-----------------------------------------------------------------
for graphing
-----------------------------------------------------------------
*/

/*
function to print the header of a json file
*/
void start_json(state_t::rule_t const &rule_1, state_t::rule_t const &rule_2, size_t n_iter) {
	// print number of iterations
	std::cout << "{\n\t\"n_iter\" : " << n_iter << ",";

	// print rules
	std::cout << "\n\t\"rules\" : [";

	auto print_rule = [](state_t::rule_t const &rule, bool next) {
		std::cout << "\n\t\t{\n\t\t\t\"name\" : \"" << rule.name << "\",";
		std::cout << "\n\t\t\t\"n_iter\" : " << rule.n_iter << ",";
		std::cout << "\n\t\t\t\"move\" : " << (rule.move ? "true" : "false") << ",";

		if (!rule.probabilist) {
			std::cout << "\n\t\t\t\"theta\" : " << rule.theta << ",";
			std::cout << "\n\t\t\t\"phi\" : " << rule.phi << ",";
			std::cout << "\n\t\t\t\"xi\" : " << rule.xi;
		} else {
			std::cout << "\n\t\t\t\"p\" : " << rule.p << ",";
			std::cout << "\n\t\t\t\"q\" : " << rule.q;
		}
		
		std::cout << "\n\t\t}";

		if (next)
			std::cout << ", ";
	};

	if (rule_1.n_iter > 0)
		print_rule(rule_1, rule_2.n_iter > 0);

	if (rule_2.n_iter > 0)
		print_rule(rule_2, false);
	
	std::cout << "\n\t],\n\t\"iterations\" : [\n\t\t";
}

/*
serialize an iteration to json
*/
void serialize_state_to_json(state_t const &s, bool last) {
	PROBA_TYPE avg_size = 0;
	PROBA_TYPE avg_size_squared = 0;

	PROBA_TYPE avg_density = 0;
	PROBA_TYPE avg_density_squared = 0;

	/* compute average values for the current iteration */
	#ifndef USE_MPRF
		#pragma omp parallel for schedule(static) \
			reduction(+ : avg_size) reduction(+ : avg_size_squared) \
			reduction(+ : avg_density) reduction(+ : avg_density_squared)
	#endif
	for (size_t gid = 0; gid < s.current_iteration.num_graphs; ++gid) {
		size_t num_nodes_ = s.current_iteration.num_nodes(gid);

		PROBA_TYPE size = (PROBA_TYPE)num_nodes_;

		// compute proba
		PROBA_TYPE real = s.current_iteration.real[gid];
		PROBA_TYPE imag = s.current_iteration.imag[gid];
		PROBA_TYPE proba = real*real + imag*imag;

		// compute density
		PROBA_TYPE density = 0;
		for (unsigned i = 0; i < size; ++i)
			density += s.current_iteration.left(gid, i) + s.current_iteration.right(gid, i);
		density /= size;

		// averages
		avg_size += proba*size;
		avg_density += proba*density;

		// standard deviation
		avg_size_squared += proba*size*size;
		avg_density_squared += proba*density*density;
	}

	PROBA_TYPE avg_size_symbolic = 0;

	/* compute averages for the symbolic iteration */
	#ifndef USE_MPRF
		#pragma omp parallel for schedule(static) reduction(+ : avg_size_symbolic)
	#endif
	for (size_t i = 0; i < s.symbolic_num_graphs; ++i) {
		size_t gid = s.next_gid[i];

		if (s.is_last_index[gid]) {
			PROBA_TYPE size = (PROBA_TYPE)s.symbolic_num_nodes[gid];

			// compute proba
			PROBA_TYPE real = s.next_real[gid];
			PROBA_TYPE imag = s.next_imag[gid];
			PROBA_TYPE proba = real*real + imag*imag;

			// average size
			avg_size_symbolic += proba * size;
		}
	}

	// compute size bias
	PROBA_TYPE size_bias = avg_size_symbolic < tolerance ? 0. : (avg_size_symbolic - avg_size) / avg_size;
	if (precision::abs(size_bias) < tolerance)
		size_bias = 0;

	// compute size standard deviation
	PROBA_TYPE std_dev_size = avg_size_squared - avg_size*avg_size;
	std_dev_size = std_dev_size <= 0 ? 0 : precision::sqrt(std_dev_size);

	// compute density standard deviation
	PROBA_TYPE std_dev_density = avg_density_squared - avg_density*avg_density;
	std_dev_density = std_dev_density <= 0 ? 0 : precision::sqrt(std_dev_density);

	// print ratio of graphs
	float ratio = s.symbolic_num_graphs == 0 ? 1 : (float)s.symbolic_num_graphs_after_interferences / (float)s.symbolic_num_graphs;
	std::cout << "{\n\t\t\t\"ratio\": " << ratio;

	// print total proba
	std::cout << ",\n\t\t\t\"total_proba\": " << s.total_proba;

	// print num graphs
	std::cout << ",\n\t\t\t\"num_graphs\": " << s.current_iteration.num_graphs;

	// print sizes
	std::cout << ",\n\t\t\t\"avg_size\": " << avg_size;
	std::cout << ",\n\t\t\t\"size_bias\": " << size_bias;
	std::cout << ",\n\t\t\t\"std_dev_size\": " << std_dev_size;

	// print densities
	std::cout << ",\n\t\t\t\"avg_density\": " << avg_density / 2;
	std::cout << ",\n\t\t\t\"std_dev_density\": " << std_dev_density / 2;

	// print separator
	std::cout << "\n\t\t}";

	// print separator
	if (!last)
		std::cout << ", ";
}

void serialize_state_to_json(state_t const &s) {
	serialize_state_to_json(s, false);
}

/*
print footer of json
*/
void end_json(state_t const &s) {
	serialize_state_to_json(s, true);
	std::cout << "\n\t]\n}\n";
}


/*
-----------------------------------------------------------------
for debugging
-----------------------------------------------------------------
*/


void print(state_t &s) {
	std::function<void(size_t, unsigned short int, bool)> const print_node = [&] (size_t gid, unsigned short int node, bool parenthesis) {
		switch (s.current_iteration.node_type(gid, node)) {
			case state_t::left_t:
				print_node(gid, s.current_iteration.left_idx(gid, node), true);
				std::cout << ".l";
				break;

			case state_t::right_t:
				print_node(gid, s.current_iteration.left_idx(gid, node), true);
				std::cout << ".r";
				break;
			
			case state_t::element_t:
				std::cout << s.current_iteration.element(gid, node);
				break;

			case state_t::pair_t:
				if (parenthesis)
					std::cout << "(";

				print_node(gid, s.current_iteration.left_idx(gid, node), true);

				std::cout << "∧";

				print_node(gid, s.current_iteration.right_idx(gid, node), true);

				if (parenthesis)
					std::cout << ")";

				break;

			default:
				throw;
		}
	};

	std::vector<size_t> gids(s.current_iteration.num_graphs);
	std::iota(gids.begin(), gids.end(), 0);

	size_t num_graphs = max_num_graph_print > 0 ? std::min(s.current_iteration.num_graphs, (size_t)max_num_graph_print) : s.current_iteration.num_graphs;

	__gnu_parallel::partial_sort(gids.begin(), gids.begin() + num_graphs, gids.end(),
	[&](size_t const &gid1, size_t const &gid2) {
		auto r1 = s.current_iteration.real[gid1];
		auto i1 = s.current_iteration.imag[gid1];

		auto r2 = s.current_iteration.real[gid2];
		auto i2 = s.current_iteration.imag[gid2];

		return r1*r1 + i1*i1 > r2*r2 + i2*i2;
	});

	for (int i = 0; i < num_graphs; ++i) {
		size_t gid = gids[i];

		if (verbose >= PRINT_DEBUG_LEVEL_3) {
			printf("\ngid:%ld, n:", gid);
			for (size_t j = s.current_iteration.node_begin[gid]; j < s.current_iteration.node_begin[gid + 1]; ++j)
				printf("%d,", s.current_iteration.node_id_c[j]);

			printf("  ");

			for (size_t j = s.current_iteration.sub_node_begin[gid]; j < s.current_iteration.sub_node_begin[gid + 1]; ++j) {
				std::string type;

				auto node_type = s.current_iteration.node_type(gid, j - s.current_iteration.sub_node_begin[gid]);

				if (s.current_iteration.is_trash(gid, j - s.current_iteration.sub_node_begin[gid])) {
					type = "x";
				} else
					switch (node_type) {
						case state_t::left_t:
							type = "l";
							break;

						case state_t::right_t:
							type = "r";
							break;

						case state_t::element_t:
							type = "e";
							break;

						case state_t::pair_t:
							type = "p";
							break;

						default:
							type = "!";
							break;
					}

				printf("%ld:(l:%d, r:%d, t:%s), ", j - s.current_iteration.sub_node_begin[gid], s.current_iteration.left_idx__or_element__and_has_most_left_zero__or_is_trash_[j],
					s.current_iteration.right_idx__or_type_[j],
					type.c_str());
			}

			std::cout << "\n";
		}

		PROBA_TYPE real = precision::abs(s.current_iteration.real[gid]) < tolerance ? 0 : s.current_iteration.real[gid];
		PROBA_TYPE imag = precision::abs(s.current_iteration.imag[gid]) < tolerance ? 0 : s.current_iteration.imag[gid];

		std::cout << real << (imag >= 0 ? "+" : "") << imag << "i   ";

		if (verbose >= PRINT_DEBUG_LEVEL_2 && s.symbolic_num_graphs > 0)
			std::cout << "	" << s.next_hash[s.next_gid[gid]] << "	";

		size_t num_nodes_ = s.current_iteration.num_nodes(gid);
		for (unsigned short int node = 0; node < num_nodes_; ++node) {
			std::cout << "-|" << (s.current_iteration.left(gid, node) ? "<" : " ") << "|";

			print_node(gid, s.current_iteration.node_id(gid, node), false);

			if (verbose >= PRINT_DEBUG_LEVEL_2)
				std::cout << "|" << s.current_iteration.hash(gid, s.current_iteration.node_id(gid, node));

			std::cout << "|" << (s.current_iteration.right(gid, node) ? ">" : " ") << "|-";
		}

		std::cout << "\n";
	}
}