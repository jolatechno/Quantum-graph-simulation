#pragma once

#include <vector>
#include <parallel/algorithm>
#include <parallel/numeric>
#include <boost/functional/hash.hpp>
#include <random>
#include <iostream>

#include "utils/random.hpp"
#include "utils/memory.hpp"
#include "utils/vector.hpp"
#include "utils/complex.hpp"

// debug levels
#ifndef STEP_DEBUG_LEVEL
	#define STEP_DEBUG_LEVEL 1
#endif
#ifndef PRINT_DEBUG_LEVEL_1
	#define PRINT_DEBUG_LEVEL_1 0.5
#endif
#ifndef PRINT_DEBUG_LEVEL_2
	#define PRINT_DEBUG_LEVEL_2 0.75
#endif
#ifndef PRINT_DEBUG_LEVEL_3
	#define PRINT_DEBUG_LEVEL_3 1.5
#endif

/* default variables preprocessor definition:
	- "UPSIZE_POLICY" corresponds to "upsize_policy" (described in iteration_t resize operators).
	- "DOWNSIZE_POLICY" corresponds to "downsize_policy" (described in iteration_t resize operators).
	- "SAFETY_MARGIN" correpsponds to "safety_margin" (described in the definition of "get_max_num_graphs()").
	- "MIN_BATCH_SIZE" correpsponds to "min_batch_size" which is the smallest workload for a thread.
	- "MIN_STATE_SIZE" corresponds to "min_state_size" which is the smallest size of a vector (described in iteration_t resize operators). 
*/
#ifndef UPSIZE_POLICY
	#define UPSIZE_POLICY 1.1
#endif
#ifndef DOWNSIZE_POLICY
	#define DOWNSIZE_POLICY 0.85
#endif
#ifndef SAFETY_MARGIN
	#define SAFETY_MARGIN 0.2
#endif
#ifndef MIN_STATE_SIZE
	#define MIN_STATE_SIZE 100000
#endif

#ifdef USE_MPRF
	// default tolerance
	#ifndef TOLERANCE
		#define TOLERANCE 0
	#endif

	// import
	#include "utils/mpreal.h"
	
	// namespace for math functions
	namespace precision = mpfr;

	// type
	#define PROBA_TYPE precision::mpreal

	// precision setter
	#define SET_PRECISION(precision_) PROBA_TYPE::set_default_prec(precision_);
#else
	// default tolerance
	#ifndef TOLERANCE
		#define TOLERANCE 1e-18
	#endif

	// standard type
	#define PROBA_TYPE long double

	// precision setter
	#define SET_PRECISION(precision)

	// namespace for math functions
	namespace precision = std;
#endif

#ifndef _OPENMP
	#define omp_set_nested(i)
	#define omp_get_thread_num() 0
	#define omp_get_num_thread() 1
#endif

// type definition
typedef class state state_t;
typedef char op_type_t;

// global variable definition
PROBA_TYPE tolerance = TOLERANCE;
float upsize_policy = UPSIZE_POLICY;
float downsize_policy = DOWNSIZE_POLICY;
float safety_margin = SAFETY_MARGIN;
size_t min_state_size = MIN_STATE_SIZE;

// debugging options
float verbose = 0;
int max_num_graph_print = 20;

/*
global header that can be used to define global variables from other files:
*/

#ifdef STATE_GLOBAL_HEADER
	STATE_GLOBAL_HEADER
#endif

/*
The "MID_STEP_FUNCTION(n)" function is called at the end of each step (inside a "omp single" region) with n between 0 (the first step) and the total number of step.
If not predefined, it will be defined as a debug function (that won't print for n=0).
It can be used to insert timming or debuging code in the step function:
*/

#ifndef MID_STEP_FUNCTION
	#define MID_STEP_FUNCTION(n) \
		if (n > 0 && verbose >= STEP_DEBUG_LEVEL) \
					std::cout << "step "#n"\n";
#endif

/*
number of threads
*/

int inline fast_log2(unsigned int x) {
	int i = 0;
	for(; (x >> i + 1) != 0 && i < 31; ++i) {}
	return i;
};

int inline fast_log2(size_t x) {
	int i = 0;
	for(; (x >> i + 1) != 0 && i < 63; ++i) {}
	return i;
};

const unsigned int num_threads = []() {
	int num_threads;
	#pragma omp parallel
	#pragma omp single
	num_threads = omp_get_num_threads();

	return num_threads;
}();

/*
!!!!!
What are called "sub-nodes" are nodes containers that are used to point to other node container (to generate pairs, left or right nodes).

Iteration protocol is:
  - (1): use a rule to put all operation inside of the vector "operations".

  - (2): calculate the number of child graph generated by each parent graph and populate "num_childs" (*)

  - (2.1): normalize the old iteration (which is not normalized after suppressing of graphs) here if wanted, since we need to sum over all "num_childs",
  	we can sum over all probabilities in the same reduction,
  	and then go over all graphs and divide their magnitude by the square root of the total probability.

  - (3): read the total number of child graph generated by each parent graph and populate:
   "next_gid" (gid of the future graph), "parent_gid" (gid of the parent graph) and "child_id" (the local id of the child among all its siblings).

  - (4, "symbolic iteartion"): by iterating over "next_gid" and using the rule, populate "next_hash", "next_real" and "next_imag" through a symbolic iteration (**),
  	and populate "symbolic_num_nodes" and "symbolic_num_sub_nodes" which are respectively the number of node and of sub-nodes for each new graph.

  - (5), (f), (p): using "next_hash" sum the probability ("next_real" and "next_imag") of equal graphs.
  	When sorting graphs according to "next_hash" to then sum the magnitude of graph of equal hash.
  	We then partinion the state so we only keep the graphs that accumulated the magnitude of graphs of equal hash.
	
	- (6), (p): compute the average memory usage of a graph.
  	We can then compute "max_num_graphs" according to the value of "get_free_mem_size()" and a "safety_margin" (a proportion of memory which should be left free).
		We then keep "max_num_graphs" graphs, with each graph having a probability of being kept (hopefully) proportional to its probability:
  		- generate a random number for each graph, following an given distribution (****), for which the rate is the probability of the graph.
  		- select the "max_num_graphs" graphs with the smallest previously mentioned "random number".
			
  - (7): reserve all public vectors for the new iteration by iterating over the N first "next_gid" and using "parent_gid" and "child_id",
  	and assign "node_begin" and "sub_node_begin" by accumulating "symbolic_num_nodes" and "symbolic_num_sub_nodes".

  - (8): generate all new graphs of the new state by iterating over the N first "next_gid" and using "parent_gid" and "child_id".

	- (9): swap the previous iteration with the next iteration.

(f) step that can be skiped for "fast iterations"
(p) step that have to be skiped for probabilist iteration

(*) to compute the number of child you just compute "pow(2, num_operations)"
(**) it's possible to compute the hash of a child graph without actually computing it for most rules
(***) the n_th bit of child_id corresponds to whether we do the n_th operation or not. 
(****) the optimal distribution found through experiments is "X_p = log( -log(U) / p )" (see ../../validation/)
*/

class state {
public:
	// type definition of a node
	typedef enum node_type {
		left_t = -3, // ().l
		right_t, // ().r
		element_t, // (n)
		pair_t, // () v ()
	} node_type_t;

	/* 
	vectors can have 3 different sizes :
		- (a) the number of graph (so a single element per graph), and + 1
		- (b) the total number of nodes (sum of the number of nodes for each graph)
		- (c) the total number of sub-nodes
	*/

	/* 
	definition of the iteration struct:
		- stores vector describing an iteration
		- has member functions to resize sizes (a), (b), and (c)
		- has getters and setters for each properties
	*/

	typedef struct iteration {
		size_t num_graphs = 0;

		// graph magnitude
		numa_vector<PROBA_TYPE> real; /* of size (a) */
		numa_vector<PROBA_TYPE> imag; /* of size (a) */

		// begin for each size
		numa_vector<unsigned int> node_begin; /* of size (a + 1), refers to vector of size (b) */
		numa_vector<unsigned int> sub_node_begin; /* of size (a + 1), refers to vectors of size (c) */

		// node properties
		/* !!!
		can't use bool because bit vectors aren't thread safe
		!!! */
		numa_vector</*bool*/ char> left_; /* of size (b), correspond to the presence of a particule going left at a node */
		numa_vector</*bool*/ char> right_; /* of size (b), correspond to the presence of a particule going right at a node */
		numa_vector<unsigned short int> node_id_c; /* of size (b), points to the sunode_node (c) namming the ith node (b) */

		// sub node properties
		/*
		"left_idx__or_element__and_has_most_left_zero__or_is_trash_" stores:
			- either 0 to signify that the sub-node is trash and can be written over (since 0 can't be used for any other node since it is always positive)
			- or the index of another node (for .l or .r) + 1 (to be able to read the sign of a node with index 0)
			- or the integer naming an element + 1 (to be able to read the sign of an element of name 0)
		and "has_most_left_zero" (*) which is stored through the sign (less than 0 if true).

		"right_idx__or_type_" stores:
			- either the index of an other node (for pairs), which is greater than, or equal to zero
			- or the node type if the node is not a pair (which is strictly less then zero).

		(*) "has_most_left_zero" is an arbitrary lexicographic order to create a "reference rotation of graphs".
			The node which is the "most_left_zero" is the node countaining the name "0(.l)^n" with the greatest n.
		*/
		numa_vector<short int> left_idx__or_element__and_has_most_left_zero__or_is_trash_; /* of size (c) */
		numa_vector<short int> right_idx__or_type_; /* of size (c) */
		numa_vector<size_t> node_hash; /* of size (c) */

		/*
		intermediary vectors used to generate the next iteration :
		*/

		// vector of operations
		numa_vector<op_type_t> operations; /* of size (b) */

		// number of sub-graph for each parent
		numa_vector<unsigned short int> num_childs; /* of size (a) */

		/* resize operators */
		/*
		"upsize_policy" is a multiplier (>1) that forces any upsize to add a margin to avoid frequent resize.

		"downsize_policy" is a multiplier (<1) that forces a down_size to free memory only if the freed memory exceed the downsize_policy
			(to allow memory to be freed and given back to another vector).

		"min_state_size" is the minimum size of a vector, to avoid small vectors which are bound to be resized frequently.
		*/
		// resize size (a)
		void resize_num_graphs(size_t size) {
			size = std::max(min_state_size, size); // minimum size is "min_state_size"
			if (num_childs.size() < size || // resize if we absolutly need to
			downsize_policy * num_childs.size() > size * upsize_policy) { // downsize according to the downsize_policy

				real.resize(upsize_policy * size);
				imag.resize(upsize_policy * size);
				node_begin.resize(upsize_policy * size + 1);
				sub_node_begin.resize(upsize_policy * size + 1);
				num_childs.resize(upsize_policy * size);
			}
		}

		// resize size (b)
		void resize_num_nodes(size_t size) {
			size = std::max(min_state_size, size); // minimum size is "min_state_size"
			if (node_id_c.size() < size || // resize if we absolutly need to
			downsize_policy * node_id_c.size() > size * upsize_policy) { // downsize according to the downsize_policy

				left_.resize(upsize_policy * size);
				right_.resize(upsize_policy * size);
				node_id_c.resize(upsize_policy * size);
				operations.resize(upsize_policy * size);
			}
		}

		// resize size (c)
		void resize_num_sub_nodes(size_t size) {
			size = std::max(min_state_size, size); // minimum size is "min_state_size"
			if (node_hash.size() < size || // resize if we absolutly need to
			downsize_policy * node_hash.size() > size * upsize_policy) { // downsize according to the downsize_policy

				left_idx__or_element__and_has_most_left_zero__or_is_trash_.resize(upsize_policy * size);
				right_idx__or_type_.resize(upsize_policy * size);
				node_hash.resize(upsize_policy * size);
			}
		}

		/* hashers */
		/*
		this functions is used to compute hash values without generating nodes at the symbolic iteration 
			("by_value" means from node properties and not from node index, since the node doesn't exist in memory).
		*/
		size_t inline hash_node_by_value(unsigned int gid, short int left_idx__or_element__and_has_most_left_zero, short int right_idx__or_type) const {
			size_t hash_ = 0;
			unsigned int left_idx_or_element = std::abs(left_idx__or_element__and_has_most_left_zero) - 1; // left_idx_or_element from left_idx__or_element__and_has_most_left_zero

			if (right_idx__or_type == element_t) {
				hash_ = left_idx_or_element; // if element
			} else
				hash_ = hash(gid, left_idx_or_element); // else get the hash of the node of idx "left_idx_or_element"

			if (right_idx__or_type < pair_t) {
				boost::hash_combine(hash_, right_idx__or_type); // if not a pair, combine the hash with type
			} else
				boost::hash_combine(hash_, hash(gid, right_idx__or_type)); // else combine the hash with the hash of the other node of the pair.

			return hash_;
		}
		/*
		this function is used when generating graphs after the symbolic iteration
		*/
		void inline hash_node(unsigned int gid, unsigned short int node) {
			unsigned int id = sub_node_begin[gid] + node; // memory location
			node_hash[id] = hash_node_by_value(gid, left_idx__or_element__and_has_most_left_zero__or_is_trash_[id], right_idx__or_type_[id]); // assign hash to "hash_node_by_value(...)"
		}

		/* getters */
		// sizes
		unsigned int inline num_nodes(unsigned int gid) const { return node_begin[gid + 1] - node_begin[gid]; } // num_node is the distance between the begining and the end of its node
		unsigned int inline num_sub_node(unsigned int gid) const { return sub_node_begin[gid + 1] - sub_node_begin[gid]; } // num_sub_node is the distance between the begining and the end of its sub-node

		// getter for nodes
		unsigned short int inline node_id(unsigned int gid, unsigned short int node) const { return node_id_c[node_begin[gid] + node]; }
		bool inline left(unsigned int gid, unsigned short int node) const { return left_[node_begin[gid] + node]; }
		bool inline right(unsigned int gid, unsigned short int node) const { return right_[node_begin[gid] + node]; }
		op_type_t inline operation(unsigned int gid, unsigned short int node) const { return operations[node_begin[gid] + node]; }

		// raw getters for sub-nodes
		size_t hash(unsigned int gid, unsigned short int node) const { return node_hash[sub_node_begin[gid] + node]; }
		short int inline right_idx(unsigned int gid, unsigned short int node) const { return right_idx__or_type_[sub_node_begin[gid] + node]; }
		short int inline &right_idx(unsigned int gid, unsigned short int node) { return right_idx__or_type_[sub_node_begin[gid] + node]; }
		/*
		"raw_left_idx" corresponds directly to "left_idx__or_element__and_has_most_left_zero__or_is_trash_" without any computation (which has no meaning, hence "raw").
		"right_idx" doesn't have a "raw" counterpart since it has a meaning without any computation.
		*/
		short int inline raw_left_idx(unsigned int gid, unsigned short int node) const { return left_idx__or_element__and_has_most_left_zero__or_is_trash_[sub_node_begin[gid] + node]; }
		short int inline &raw_left_idx(unsigned int gid, unsigned short int node) { return left_idx__or_element__and_has_most_left_zero__or_is_trash_[sub_node_begin[gid] + node]; }
		
		// composits getters for raw_left_idx
		/*
		"left_idx" is equivalent to "raw_left_idx" without the sign and shifted index
		*/
		unsigned short int inline left_idx(unsigned int gid, unsigned short int node) const { 
			return std::abs(raw_left_idx(gid, node)) - 1; // absolute value minus one to get rid of the sign
		}
		unsigned short int inline element(unsigned int gid, unsigned short int node) const { return left_idx(gid, node); } // alias "to left_idx(...)"
		bool inline is_trash(unsigned int gid, unsigned short int node) const { return raw_left_idx(gid, node) == 0; }	// trash if left_idx__or_element__and_has_most_left_zero__or_is_trash_ is zero
		bool inline has_most_left_zero(unsigned int gid, unsigned short int node) const {
			return raw_left_idx(gid, node) < 0; // true if left_idx__or_element__and_has_most_left_zero__or_is_trash_ < 0
		}

		// composits getters for raw_right_idx
		node_type_t inline node_type(unsigned int gid, unsigned short int node) const {
			return std::min((node_type_t)right_idx(gid, node), pair_t); // pair if right_idx__or_type_ >= 0, otherwise the type is dorectly right_idx__or_type_
		}

		/* setters */
		// setters for nodes
		void inline set_node_id(unsigned int gid, unsigned short int node, unsigned short int value) { node_id_c[node_begin[gid] + node] = value; }
		void inline set_left(unsigned int gid, unsigned short int node, bool value) { left_[node_begin[gid] + node] = value; }
		void inline set_right(unsigned int gid, unsigned short int node, unsigned short int value) { right_[node_begin[gid] + node] = value; }
		void inline set_operation(unsigned int gid, unsigned short int node, op_type_t value) { operations[node_begin[gid] + node] = value; }

		// raw setters for sub-nodes
		void inline set_raw_left(unsigned int gid, unsigned short int node, short int value) { raw_left_idx(gid, node) = value; }
		
		// composite setters for raw_left_idx
		void inline set_is_trash(unsigned int gid, unsigned short int node) { set_raw_left(gid, node, 0); } // set to zero
		void inline set_left_idx(unsigned int gid, unsigned short int node, unsigned short int value) { set_raw_left(gid, node, value + 1); } // set value, including the index shift
		void inline set_element(unsigned int gid, unsigned short int node, unsigned short int value) { set_left_idx(gid, node, value); } // alias for "set_left_idx(...)"
		void inline set_has_most_left_zero(unsigned int gid, unsigned short int node, bool has_most_left_zero_) {
			short int &temp = raw_left_idx(gid, node);

			if (has_most_left_zero_ == (temp > 0)) // switch the sign if it doesn't correspond
				temp *= -1;
		}

		// composite setters for raw_right_idx
		void inline set_right_idx(unsigned int gid, unsigned short int node, unsigned short int value) { right_idx(gid, node) = value; }
		void inline set_type(unsigned int gid, unsigned short int node, node_type_t value) { right_idx(gid, node) = value; }
		
		/* randomize function */
		void randomize() {
			// random genearator
			size_t size = left_.size();
			for (int i = 0; i < size; ++i) {
				/* throw a coin to decide the presence of a particule going right or left on each node of each graph */
				left_[i] = std::rand() & 1;
				right_[i] = std::rand() & 1;
			}
		}
	} iteration_t;

	/* two iterations are stored in a state and are swaped at the end of each step */
	iteration_t current_iteration, next_iteration;

	/* constructor for multiple graphs of a given size */
	state(unsigned int size, unsigned int n) {
		current_iteration.num_graphs = n;

		// resize current_iteration
		current_iteration.resize_num_graphs(n);
		current_iteration.resize_num_nodes(size*n);
		current_iteration.resize_num_sub_nodes(size*n);

		// set intitial vector values
		current_iteration.real[0] = 1 / precision::sqrt((PROBA_TYPE)n);
		current_iteration.node_begin[0] = 0;
		current_iteration.sub_node_begin[0] = 0;

		// set the node type for all nodes
		std::fill(current_iteration.right_idx__or_type_.begin(),
			current_iteration.right_idx__or_type_.begin() + size*n,
			element_t);

		// fill graphs with empty nodes
		std::fill(current_iteration.left_.begin(),
			current_iteration.left_.begin() + size*n,
			false);
		std::fill(current_iteration.right_.begin(),
			current_iteration.right_.begin() + size*n,
			false);

		for (unsigned int gid = 0; gid < n; ++gid) {
			// set the magnitude each graphs
			current_iteration.real[gid] = current_iteration.real[0]; current_iteration.imag[gid] = 0;

			// giving "size" nodes and sub-nodes for the graph "gid" 
			current_iteration.node_begin[gid + 1] = current_iteration.node_begin[gid] + size;
			current_iteration.sub_node_begin[gid + 1] = current_iteration.sub_node_begin[gid] + size;

			// initiate the sub-node id of each node
			std::iota(current_iteration.node_id_c.begin() + current_iteration.node_begin[gid],
				current_iteration.node_id_c.begin() + current_iteration.node_begin[gid + 1],
				0);

			// intiate the name of each sub-node
			std::iota(current_iteration.left_idx__or_element__and_has_most_left_zero__or_is_trash_.begin() + current_iteration.node_begin[gid],
				current_iteration.left_idx__or_element__and_has_most_left_zero__or_is_trash_.begin() + current_iteration.node_begin[gid + 1],
				1);

			// set has_most_left_zero for the first node of each graph
			current_iteration.left_idx__or_element__and_has_most_left_zero__or_is_trash_[current_iteration.node_begin[gid]] = -1;

			// hash each node
			for (unsigned int node = 0; node < size; ++node)
				current_iteration.hash_node(gid, node);
		}
	}

	/* vector for work sharing */
	std::vector<unsigned int> work_sharing_begin = std::vector<unsigned int>(num_threads + 1);

	/* constructor for a single graph of a given size */
	state(unsigned int size) : state(size, 1) {}

	/* randomize function */
	void randomize() { current_iteration.randomize(); }

	/* 
	symbolic iteration: 
		- vectors for temporary properties stored at the symbolic iteration
		- member function to resize the number of graph at symbolic iteration
	*/

	// number of graphs
	size_t symbolic_num_graphs = 0;

	// new graphs
	/*
	"is_last_index[gid]" is true if the graph "gid" is the graph which will accumulate the magnitude of the graphs of equal hash
	*/
	numa_vector</*bool*/ char> is_last_index; /* of size (a) for the symbolic iteration */
	numa_vector<unsigned int> next_gid; /* of size (a) for the symbolic iteration */
	numa_vector<unsigned int> parent_gid; /* of size (a) for the symbolic iteration */
	numa_vector<unsigned short int> child_id; /* of size (a) for the symbolic iteration */

	// new graph hash
	numa_vector<size_t> next_hash; /* of size (a) for the symbolic iteration */

	// new graph random selector
	numa_vector<double> random_selector; /* of size (a) for the symbolic iteration */

	// new graph magnitude
	numa_vector<PROBA_TYPE> next_real; /* of size (a) for the symbolic iteration */
	numa_vector<PROBA_TYPE> next_imag; /* of size (a) for the symbolic iteration */

	// size for each size
	numa_vector<unsigned int> symbolic_num_nodes; /* of size (a + 1), refers to vector of size (b) */
	numa_vector<unsigned int> symbolic_num_sub_nodes; /* of size (a + 1), refers to vectors of size (c) */

	// resize operator
	void resize_symbolic_num_graphs(size_t size) {
		size = std::max(min_state_size, size); // minimum size is "min_state_size"
		if (next_gid.size() < size || // resize if we absolutly need to
		downsize_policy * next_gid.size() > size * upsize_policy) { // downsize according to the downsize_policy

			next_gid.resize(upsize_policy * size);
			parent_gid.resize(upsize_policy * size);
			child_id.resize(upsize_policy * size);
			is_last_index.resize(upsize_policy * size);
			next_hash.resize(upsize_policy * size);
			next_real.resize(upsize_policy * size);
			next_imag.resize(upsize_policy * size);
			symbolic_num_nodes.resize(upsize_policy * size);
			symbolic_num_sub_nodes.resize(upsize_policy * size);
			random_selector.resize(upsize_policy * size);
		}

		// initialize next_gid with 1, 2, 3....
		std::iota(next_gid.begin(), next_gid.begin() + size, 0);
	}

/* 
rule virtual class definition:
	- A rule can be "probabilist" or "quantum".
	- For each rule, the "none" operation has to be represented by 0
	- It has virtual member functions that needs to be overloaded by each individual rule.

Non-virtual member functions are:
	- Constructor (for both probabilist and quantum rules).
	- "multiply_proba(PROBA_TYPE &real, PROBA_TYPE &imag, op_type_t op, bool do_)" to multiply a magnitude by the rule's matrix (according to the operation type).
	- "num_childs()" which is used at step 2 of the iteration.
	- "do_operation(unsigned short int &child_id)" that check if some operation should be done or not according to the "child_id", and the type of rule.
	- "write_operation(op_type_t op)" which apply the probabilist decision if the rule is probabilist, else returns op.
*/
	typedef class rule {
	private:
		/* random generator */
		mutable unfiorm random_generator;

	public:
		/* flag to determine the type of rule */
		bool probabilist = false;
		bool classical = false;
		bool identity = false;

		/* parameters of a stochiastic matrix */
		PROBA_TYPE p = 1; // probability of the first operation
		PROBA_TYPE q = 1; // probability of the second operation

		/* parameters of a unitary matrix */
		PROBA_TYPE do_real = 1; // non-diagonal terms
		PROBA_TYPE do_imag = 0;
		PROBA_TYPE do_not_real = 0; // diagonal terms
		PROBA_TYPE do_not_imag = 0;

		/* parameters for print */
		PROBA_TYPE theta, phi, xi;
		std::string name = "";
		bool move = true; // wether to move or not after each application of the rule
		unsigned int n_iter = 0; // number of application of the rule for each step

		/* constructors */
		// constructors for a unitary matrix
		rule(PROBA_TYPE theta_, PROBA_TYPE phi_, PROBA_TYPE xi_) : theta(theta_), phi(phi_), xi(xi_) {
			do_real = precision::sin(theta)* precision::cos(phi);
			do_imag = precision::sin(theta)* precision::sin(phi);
			do_not_real = precision::cos(theta)* precision::cos(xi);
			do_not_imag = precision::cos(theta)* precision::sin(xi);

			// check for identity
			identity = precision::abs(do_real) <= tolerance && precision::abs(do_imag) <= tolerance;

			// check for classical rule
			classical = precision::abs(do_not_real) <= tolerance && precision::abs(do_not_imag) <= tolerance;
		}

		// probabilist constructor (p != q)
		rule(PROBA_TYPE p_, PROBA_TYPE q_) : p(p_), q(q_), probabilist(true) {
			do_real = precision::sqrt(p);
			do_imag = precision::sqrt(q);
			do_not_real = precision::sqrt(1 - p);
			do_not_imag = precision::sqrt(1 - q);
		}

		// probabilist constructor (p == q)
		rule(PROBA_TYPE p_) : rule(p_, p_) {}

		// empty constructor
		rule() {}

		/* multiply the magnitude of a graph according to the operation and the rule */
		void inline multiply_proba(PROBA_TYPE &real, PROBA_TYPE &imag, op_type_t op /* either 0 or 1 */, bool do_) const {
			if (!probabilist) {

				/* quantum case */
				PROBA_TYPE sign = op ? 1 : -1;
				if (do_) {
					time_equal(real, imag, do_real, sign*do_imag);
				} else
					time_equal(real, imag, sign*do_not_real, do_not_imag);

				/* 
				representation of the unitary matrix:
				(	  do_not_real + i*do_not_imag	,			do_real + i*do_imag				)
				(   	do_real - i*do_imag 			,	-do_not_real + i*do_not_imag	)
				*/
			}
		}

		/* 
		probabilist:
			- randomly chooses whether to do operation or not according to p and q
		classical / quantum:
			- always write the operation
		*/
		op_type_t inline write_operation(op_type_t op) const {
			if (!probabilist || op == 0)
				return op;
			
			/* generate random number */
			if (random_generator() < (op == 1 ? p : q))
				return op;

			return 0; 
		}

		/*
		quantum:
			- check whether to do an operation or not (return the n_th bit of child_id)
		classical / probabilist:
			- always do the operation
		*/
		bool inline do_operation(unsigned short int &child_id) const {
			/* check if the rule is classical */
			if (probabilist || classical)
				return true;

			/* check if the rule is the identity */
			if (identity)
				return false;

			/* return the first bit and bit shift, effectivly returning the n_th bit */
			bool do_ = child_id & 1;
			child_id >>= 1;

			return do_;
		}

		/* step (1) */
		// virtual function to be overloaded
		virtual op_type_t operation(iteration_t const &s, unsigned int gid, unsigned short int node) const { return '\0'; }

		/* step (2) */
		/*
		probabilist / classical:
			- return 1 (since there is only one child)
		quantum:
			- count the number of operations in the graph (n), and returns 2^n (since each operation can be done or not independantly)
		*/
		unsigned short int num_childs(iteration_t const &s, unsigned int gid) const {
			/* check for "classical case" */
			if (probabilist || classical || identity)
				return 1;

			/* count operations */
			unsigned int num_op = 0;
			unsigned int num_nodes_ = s.num_nodes(gid);
			for (unsigned int node = 0; node < num_nodes_; ++node)
				num_op += s.operation(gid, node) != 0; // 0 is the "none" operation for all dynamics

			/* 2^n_op childs */
			return 1 << num_op;
		}

		/* step (4) */
		/* symbolic iteration */
		// virtual function to be overloaded
		virtual void child_properties(size_t& hash_,
			PROBA_TYPE& real, PROBA_TYPE& imag,
			unsigned int& num_nodes, unsigned int& num_sub_node,
			iteration_t const &s, unsigned int parent_id, unsigned short int child_id) const {}

		/* step (8) */
		/* generating actual graphs */
		// virtual function to be overloaded
		virtual void populate_new_graph(iteration_t const &s, iteration_t &next_iteration, unsigned int next_gid, unsigned int parent_id, unsigned short int child_id) const {}
	} rule_t;


	/* compute the maximum number of graph that can fit in memory accross two iterations */
	long int inline get_max_num_graphs() const {
		// get the free memory and the total amount of memory...
		auto [total_memory, free_mem] = get_mem_usage_and_free_mem();

		// and according to the "safety_margin" (a proportion of total memory) compute the total delta between the amount free memory and the target
		long int mem_difference = free_mem - total_memory*safety_margin;

		// constant mem usage per vector elements for each size
		static const long int graph_mem_usage = 2*sizeof(PROBA_TYPE) + 2*sizeof(unsigned int) + sizeof(unsigned short int);
		static const long int node_mem_usage = 2*sizeof(char) + sizeof(unsigned short int) + sizeof(op_type_t);
		static const long int sub_node_mem_usage = 2*sizeof(short int) + sizeof(size_t);
		static const long int symbolic_mem_usage = sizeof(char) + 3*sizeof(unsigned int) + sizeof(unsigned short int) + sizeof(size_t) + 2*sizeof(PROBA_TYPE) + sizeof(double);

		long int mem_usage_per_graph = (graph_mem_usage + // usage for a single graph
			(node_mem_usage * current_iteration.node_begin[current_iteration.num_graphs] + // usage for a node * total number of nodes
			sub_node_mem_usage * current_iteration.sub_node_begin[current_iteration.num_graphs] + // usage for a sub-node * total number of sub-nodes
			symbolic_mem_usage * symbolic_num_graphs / 2) // usage for a graph at the symbolic iteration  * total number of graphs at the symbolic iteration, divided by two since two iteration coexists
			/ current_iteration.num_graphs // divided by the number of graphs at the last step to obtain per-graph memory usage
			) * upsize_policy; // time the "upsize_policy" since it adds an memory inneficiency

		// get the total number of graphs that can fit in memory,
		// by adding the number of graphs that can fit in the "mem_difference" to the number of graphs in both iterations
		// then divided it by two since we need to have two iteartions at the same time.
		long int max_num_graph = (current_iteration.num_graphs + next_iteration.num_graphs + mem_difference / mem_usage_per_graph) / 2;

		if (max_num_graph <= 0)
			max_num_graph = current_iteration.num_graphs;

		return std::max(max_num_graph, (long int)min_state_size);
	}

	/* step function */
	void inline step(rule_t const &rule) { step(rule, true); }
	void inline step(rule_t const &rule, bool normalize) { step(rule, normalize, 0, true, false); }
	void inline step(rule_t const &rule, bool normalize, long int max_num_graphs) { step(rule, normalize, max_num_graphs, false, false); }

	void inline fast_step(rule_t const &rule) { fast_step(rule, true); }
	void inline fast_step(rule_t const &rule, bool normalize) { step(rule, normalize, 0, true, true); }

private:
	void step(rule_t const &rule, bool normalize, long int max_num_graphs, bool overwrite_max_num_graphs, bool fast) {
		/* check for calssical cases */
		if (rule.identity)
			return;

		// set the proba to 1 if we won't normalize, else 0 since we need to accumulate the probabilities
		PROBA_TYPE total_proba = !normalize;

		symbolic_num_graphs = 0;

		/* allow nested parallism for __gnu_parallel inside omp single */
		omp_set_nested(3);

		/* !!!!!!!!!!!!!!!!
		step (1) 
		 !!!!!!!!!!!!!!!! */

		MID_STEP_FUNCTION(0);

		#pragma omp parallel
		{

			/* get operations for each node of each graph */
			#pragma omp for schedule(static)
			for (unsigned int gid = 0; gid < current_iteration.num_graphs; ++gid) {
				auto num_nodes_ = current_iteration.num_nodes(gid);

				/* get operations for each nodes of each graph */
				for (unsigned int node = 0; node < num_nodes_; ++node)
					current_iteration.set_operation(gid, node, rule.operation(current_iteration, gid, node));
			}

			/* !!!!!!!!!!!!!!!!
			step (2) 
			 !!!!!!!!!!!!!!!! */

			#pragma omp single
			{
				MID_STEP_FUNCTION(1);
			}

			#ifndef USE_MPRF
				#pragma omp for schedule(static) reduction(+:symbolic_num_graphs) reduction(+:total_proba)
			#else
				#pragma omp single
			#endif
			for (unsigned int gid = 0; gid < current_iteration.num_graphs; ++gid) {
				/* get the number of child for each graph */
				current_iteration.num_childs[gid] = rule.num_childs(current_iteration, gid);

				/* compute the total number of child in parallel */
				symbolic_num_graphs += current_iteration.num_childs[gid];

				/* compute total proba */
				if (normalize) {
					PROBA_TYPE r = current_iteration.real[gid];
					PROBA_TYPE i = current_iteration.imag[gid];

					total_proba += r*r + i*i;
				}
			}

			/* !!!!!!!!!!!!!!!!
			step (2.1) 
			 !!!!!!!!!!!!!!!! */

			if (normalize) {
				#pragma omp single
				total_proba = precision::sqrt(total_proba);
				
				/* normalize by divinding magnitudes by the square root of the total probability */
				#pragma omp for schedule(static)
				for (unsigned int gid = 0; gid < current_iteration.num_graphs; ++gid) {
					current_iteration.real[gid] /= total_proba;
					current_iteration.imag[gid] /= total_proba;
				}
			}

			/* !!!!!!!!!!!!!!!!
			step (3) 
			 !!!!!!!!!!!!!!!! */
			
			#pragma omp single
			{
				MID_STEP_FUNCTION(2);

				/* resize variables with the right_ number of elements */
				resize_symbolic_num_graphs(symbolic_num_graphs);
				
				unsigned int id = 0;
				for (unsigned int gid = 0; gid < current_iteration.num_graphs; ++gid) {
					unsigned int const num_child = current_iteration.num_childs[gid];
					
					/* assign parent ids and child ids for each child */
					for (unsigned int child_id_ = 0; child_id_ < num_child; ++child_id_, ++id) {
						parent_gid[id] = gid;
						child_id[id] = child_id_;
					}
				}

				/* !!!!!!!!!!!!!!!!
				step (4) 
				 !!!!!!!!!!!!!!!! */

				MID_STEP_FUNCTION(3);
			}

			/* symbolic iteration :
				compute properties of each possible future graph */ 
			#pragma omp for schedule(static)
			for (unsigned int gid = 0; gid < symbolic_num_graphs; ++gid)
				rule.child_properties(next_hash[gid],
					next_real[gid], next_imag[gid],
					symbolic_num_nodes[gid], symbolic_num_sub_nodes[gid],
					current_iteration, parent_gid[gid], child_id[gid]);

			/* !!!!!!!!!!!!!!!!
			step (5) 
			 !!!!!!!!!!!!!!!! */

			#pragma omp single
			{
				MID_STEP_FUNCTION(4);
			}

			/* no need to compute interference if we are in the probabilist case */
			if (!rule.probabilist) {
				if (!fast) {
					int log_num_thread = fast_log2(num_threads);
					#pragma omp single
					{
						work_sharing_begin[0] = 0;
						work_sharing_begin[num_threads] = symbolic_num_graphs;

						/* share work according to hash */
						for (int shift = 0; shift < log_num_thread; ++shift) {
							/* assuming thread_id is a power of two, x % num_threads = x & (thread_id - 1) */
							unsigned int num_partition = 1 << shift;
							unsigned int const partition_width = num_threads / num_partition;

							#pragma omp parallel for schedule(static) num_threads(num_partition)
							for (unsigned int partition = 0; partition < num_partition; ++partition) {
								unsigned int begin = partition*partition_width;
								unsigned int end = (partition + 1)*partition_width;
								unsigned int middle = (begin + end)/2;

								/* set number of thread for subsequent parallel partition */
								omp_set_num_threads(partition_width);

								auto partitioned_it = __gnu_parallel::partition(next_gid.begin() + work_sharing_begin[begin],
								next_gid.begin() + work_sharing_begin[end],
								[&](unsigned int const &gid) {
									return (next_hash[gid] >> shift) & 1;
								});

								work_sharing_begin[middle] = std::distance(next_gid.begin(), partitioned_it);
							}
						}
					}

					unsigned int thread_id = omp_get_thread_num();
				
					if (work_sharing_begin[thread_id] < work_sharing_begin[thread_id + 1]) {
						unsigned int *max_idx = std::max_element(next_gid.begin() + work_sharing_begin[thread_id],
							next_gid.begin() + work_sharing_begin[thread_id + 1],
							[&](unsigned int gid1, unsigned int gid2) {
								return next_hash[gid1] > next_hash[gid2];
							});
						unsigned int max_shift = fast_log2(next_hash[*max_idx]);

						/* sort graphs hash to compute interference */
						/* using radix lsd sort */
						for (unsigned int shift = log_num_thread + 1; shift < max_shift; ++shift)
							std::stable_partition(next_gid.begin() + work_sharing_begin[thread_id],
								next_gid.begin() + work_sharing_begin[thread_id + 1],
								[&](unsigned int gid) {
									return (next_hash[gid] >> shift) & 1;
								});

						/* set is_last_index of the last graph */
						is_last_index[next_gid[work_sharing_begin[thread_id + 1] - 1]] = true;

						/* compute is_last_index */
						for (unsigned int gid = work_sharing_begin[thread_id]; gid < work_sharing_begin[thread_id + 1] - 1; ++gid)
							is_last_index[next_gid[gid]] = next_hash[next_gid[gid]] != next_hash[next_gid[gid + 1]];

						/* partial sum over the interval since we know it starts and end at unique graphs */
						PROBA_TYPE sign;
						unsigned int last_id = next_gid[work_sharing_begin[thread_id]];
						for (unsigned int gid = work_sharing_begin[thread_id] + 1; gid < work_sharing_begin[thread_id + 1]; ++gid) {
							unsigned int id = next_gid[gid];
							sign = !is_last_index[last_id];

							/* add probabilites of graph with equal hashes */
							next_real[id] += sign*next_real[last_id];
							next_imag[id] += sign*next_imag[last_id];

							last_id = id;
						}
					}	
				}

				#pragma omp barrier

				#pragma omp single
				{
					auto partitioned_it = next_gid.begin() + symbolic_num_graphs;
					if (!fast)
						/* get all unique graphs with a non zero probability */
						partitioned_it = __gnu_parallel::partition(next_gid.begin(), partitioned_it,
						[&](unsigned int const &gid) {
							/* check if graph is unique */
							if (!is_last_index[gid])
								return false;

							/* check for zero probability */
							PROBA_TYPE r = next_real[gid];
							PROBA_TYPE i = next_imag[gid];

							return r*r + i*i > tolerance; 
						});

					long int next_num_graphs = std::distance(next_gid.begin(), partitioned_it);
							
					/* !!!!!!!!!!!!!!!!
					step (6) 
					 !!!!!!!!!!!!!!!! */

					MID_STEP_FUNCTION(5);

					if (overwrite_max_num_graphs)
						max_num_graphs = get_max_num_graphs();

					if (max_num_graphs > 0 && next_num_graphs > max_num_graphs) {

						/* generate random selectors */
						#pragma omp parallel for schedule(static)
						for (auto gid_it = next_gid.begin(); gid_it != partitioned_it; ++gid_it)  {
							PROBA_TYPE r = next_real[*gid_it];
							PROBA_TYPE i = next_imag[*gid_it];

							float random_value = (float)next_hash[*gid_it] / 18446744073709551616.;
							random_selector[*gid_it] = precision::log( -precision::log(1 - random_value) / (r*r + i*i));
						} 

						/* select graphs according to random selectors */
						__gnu_parallel::nth_element(next_gid.begin(), next_gid.begin() + max_num_graphs, partitioned_it,
						[&](unsigned int const &gid1, unsigned int const &gid2) {
							return random_selector[gid1] < random_selector[gid2];
						});

						next_num_graphs = max_num_graphs;
					}

					next_iteration.num_graphs = next_num_graphs;

					/* !!!!!!!!!!!!!!!!
					step (7) 
					 !!!!!!!!!!!!!!!! */

					MID_STEP_FUNCTION(6);

					/* sort to make memory access more continuous */
					__gnu_parallel::sort(next_gid.begin(), next_gid.begin() + next_iteration.num_graphs);

					/* resize new step variables */
					next_iteration.resize_num_graphs(next_iteration.num_graphs);
				}
			} else
				#pragma omp single
				{
					MID_STEP_FUNCTION(5);
					MID_STEP_FUNCTION(6);

					/* same number of graphs for a probabilist simulation */
					next_iteration.num_graphs = symbolic_num_graphs;
					next_iteration.resize_num_graphs(next_iteration.num_graphs);
				}

			/* prepare for partial sum */
			#pragma omp for schedule(static)
			for (unsigned int gid = 0; gid < next_iteration.num_graphs; ++gid) {
				unsigned int id = next_gid[gid];

				next_iteration.node_begin[gid + 1] = symbolic_num_nodes[id];
				next_iteration.sub_node_begin[gid + 1] = symbolic_num_sub_nodes[id];

				/* assign magnitude */
				next_iteration.real[gid] = next_real[id];
				next_iteration.imag[gid] = next_imag[id];
			}

			#pragma omp single
			{
				/* compute the partial sums to get new node_begin and sub_node_begin */
				next_iteration.node_begin[0] = 0;
				__gnu_parallel::partial_sum(next_iteration.node_begin.begin() + 1, next_iteration.node_begin.begin() + next_iteration.num_graphs + 1, next_iteration.node_begin.begin() + 1);

				next_iteration.sub_node_begin[0] = 0;
				__gnu_parallel::partial_sum(next_iteration.sub_node_begin.begin() + 1, next_iteration.sub_node_begin.begin() + next_iteration.num_graphs + 1, next_iteration.sub_node_begin.begin() + 1);

				/* resize new step variables */
				next_iteration.resize_num_nodes(next_iteration.node_begin[next_iteration.num_graphs]);
				next_iteration.resize_num_sub_nodes(next_iteration.sub_node_begin[next_iteration.num_graphs]);

				/* !!!!!!!!!!!!!!!!
				step (8) 
				 !!!!!!!!!!!!!!!! */

				MID_STEP_FUNCTION(7);
			}

			#pragma omp for schedule(static)
			for (unsigned int gid = 0; gid < next_iteration.num_graphs; ++gid) {
				auto id = next_gid[gid];
				/* populate graphs */
				rule.populate_new_graph(current_iteration, next_iteration, gid, parent_gid[id], child_id[id]);
			}
		}

		MID_STEP_FUNCTION(8);

		/* !!!!!!!!!!!!!!!!
		step (9) 
		 !!!!!!!!!!!!!!!! */

		/* swap states */
		std::swap(current_iteration, next_iteration);
	}
};


/*
-----------------------------------------------------------------
for graphing
-----------------------------------------------------------------
*/

/*
function to print the header of a json file
*/
void start_json(state_t::rule_t const &rule_1, state_t::rule_t const &rule_2, unsigned int n_iter) {
	// print number of iterations
	std::cout << "{\n\t\"n_iter\" : " << n_iter << ",";

	// print rules
	std::cout << "\n\t\"rules\" : [";

	auto print_rule = [](state_t::rule_t const &rule, bool next) {
		std::cout << "\n\t\t{\n\t\t\t\"name\" : \"" << rule.name << "\",";
		std::cout << "\n\t\t\t\"n_iter\" : " << rule.n_iter << ",";
		std::cout << "\n\t\t\t\"move\" : " << (rule.move ? "true" : "false") << ",";

		if (!rule.probabilist) {
			std::cout << "\n\t\t\t\"theta\" : " << rule.theta << ",";
			std::cout << "\n\t\t\t\"phi\" : " << rule.phi << ",";
			std::cout << "\n\t\t\t\"xi\" : " << rule.xi;
		} else {
			std::cout << "\n\t\t\t\"p\" : " << rule.p << ",";
			std::cout << "\n\t\t\t\"q\" : " << rule.q;
		}
		
		std::cout << "\n\t\t}";

		if (next)
			std::cout << ", ";
	};

	if (rule_1.n_iter > 0)
		print_rule(rule_1, rule_2.n_iter > 0);

	if (rule_2.n_iter > 0)
		print_rule(rule_2, false);
	
	std::cout << "\n\t],\n\t\"iterations\" : [\n\t\t";
}

/*
serialize an iteration to json
*/
void serialize_state_to_json(state_t const &s, bool last) {
	PROBA_TYPE avg_size = 0;
	PROBA_TYPE avg_size_squared = 0;

	PROBA_TYPE avg_density = 0;
	PROBA_TYPE avg_density_squared = 0;

	PROBA_TYPE total_proba = 0;

	/* compute average values for the current iteration */
	#ifndef USE_MPRF
		#pragma omp parallel for schedule(static) \
			reduction(+ : avg_size) reduction(+ : avg_size_squared) \
			reduction(+ : avg_density) reduction(+ : avg_density_squared) \
			reduction(+ : total_proba)
	#endif
	for (unsigned int gid = 0; gid < s.current_iteration.num_graphs; ++gid) {
		unsigned int num_nodes_ = s.current_iteration.num_nodes(gid);

		PROBA_TYPE size = (PROBA_TYPE)num_nodes_;

		// compute proba
		PROBA_TYPE real = s.current_iteration.real[gid];
		PROBA_TYPE imag = s.current_iteration.imag[gid];
		PROBA_TYPE proba = real*real + imag*imag;

		// compute density
		PROBA_TYPE density = 0;
		for (unsigned i = 0; i < size; ++i)
			density += s.current_iteration.left(gid, i) + s.current_iteration.right(gid, i);
		density /= size;

		// averages
		avg_size += proba*size;
		avg_density += proba*density;

		// standard deviation
		avg_size_squared += proba*size*size;
		avg_density_squared += proba*density*density;

		// total proba
		total_proba += proba;
	}

	// correct according to total_proba
	avg_size /= total_proba;
	avg_size_squared /= total_proba;
	avg_density /= total_proba;
	avg_density_squared /= total_proba;

	PROBA_TYPE avg_size_symbolic = 0;
	PROBA_TYPE symbolic_total_proba = 0;

	/* compute averages for the symbolic iteration */
	#ifndef USE_MPRF
		#pragma omp parallel for schedule(static) reduction(+ : avg_size_symbolic) reduction(+ : symbolic_total_proba)
	#endif
	for (unsigned int i = 0; i < s.symbolic_num_graphs; ++i) {
		unsigned int gid = s.next_gid[i];

		if (s.is_last_index[gid]) {
			PROBA_TYPE size = (PROBA_TYPE)s.symbolic_num_nodes[gid];

			// compute proba
			PROBA_TYPE real = s.next_real[gid];
			PROBA_TYPE imag = s.next_imag[gid];
			PROBA_TYPE proba = real*real + imag*imag;

			// average size
			avg_size_symbolic += proba * size;

			// total proba
			symbolic_total_proba += proba;
		}
	}

	// correct according to total proba
	if (symbolic_total_proba == 0)
		symbolic_total_proba = 1;
	avg_size_symbolic /= symbolic_total_proba;

	// compute size bias
	PROBA_TYPE size_bias = avg_size_symbolic < tolerance ? 0. : (avg_size_symbolic - avg_size) / avg_size;
	if (precision::abs(size_bias) < tolerance)
		size_bias = 0;

	// compute size standard deviation
	PROBA_TYPE std_dev_size = avg_size_squared - avg_size*avg_size;
	std_dev_size = std_dev_size <= 0 ? 0 : precision::sqrt(std_dev_size);

	// compute density standard deviation
	PROBA_TYPE std_dev_density = avg_density_squared - avg_density*avg_density;
	std_dev_density = std_dev_density <= 0 ? 0 : precision::sqrt(std_dev_density);

	// print ratio of graphs
	float ratio = s.symbolic_num_graphs == 0 ? 1 : (float)s.current_iteration.num_graphs / (float)s.symbolic_num_graphs;
	std::cout << "{\n\t\t\t\"ratio\": " << ratio;

	// print total proba
	std::cout << ",\n\t\t\t\"total_proba\": " << total_proba;

	// print num graphs
	std::cout << ",\n\t\t\t\"num_graphs\": " << s.current_iteration.num_graphs;

	// print sizes
	std::cout << ",\n\t\t\t\"avg_size\": " << avg_size;
	std::cout << ",\n\t\t\t\"size_bias\": " << size_bias;
	std::cout << ",\n\t\t\t\"std_dev_size\": " << std_dev_size;

	// print densities
	std::cout << ",\n\t\t\t\"avg_density\": " << avg_density / 2;
	std::cout << ",\n\t\t\t\"std_dev_density\": " << std_dev_density / 2;

	// print separator
	std::cout << "\n\t\t}";

	// print separator
	if (!last)
		std::cout << ", ";
}

void serialize_state_to_json(state_t const &s) {
	serialize_state_to_json(s, false);
}

/*
print footer of json
*/
void end_json(state_t const &s) {
	serialize_state_to_json(s, true);
	std::cout << "\n\t]\n}\n";
}


/*
-----------------------------------------------------------------
for debugging
-----------------------------------------------------------------
*/


void print(state_t &s) {
	std::function<void(unsigned int, unsigned short int, bool)> const print_node = [&] (unsigned int gid, unsigned short int node, bool parenthesis) {
		switch (s.current_iteration.node_type(gid, node)) {
			case state_t::left_t:
				print_node(gid, s.current_iteration.left_idx(gid, node), true);
				std::cout << ".l";
				break;

			case state_t::right_t:
				print_node(gid, s.current_iteration.left_idx(gid, node), true);
				std::cout << ".r";
				break;
			
			case state_t::element_t:
				std::cout << s.current_iteration.element(gid, node);
				break;

			case state_t::pair_t:
				if (parenthesis)
					std::cout << "(";

				print_node(gid, s.current_iteration.left_idx(gid, node), true);

				std::cout << "∧";

				print_node(gid, s.current_iteration.right_idx(gid, node), true);

				if (parenthesis)
					std::cout << ")";

				break;

			default:
				throw;
		}
	};

	std::vector<unsigned int> gids(s.current_iteration.num_graphs);
	std::iota(gids.begin(), gids.end(), 0);

	unsigned int num_graphs = max_num_graph_print > 0 ? std::min(s.current_iteration.num_graphs, (size_t)max_num_graph_print) : s.current_iteration.num_graphs;

	__gnu_parallel::partial_sort(gids.begin(), gids.begin() + num_graphs, gids.end(),
	[&](unsigned int const &gid1, unsigned int const &gid2) {
		auto r1 = s.current_iteration.real[gid1];
		auto i1 = s.current_iteration.imag[gid1];

		auto r2 = s.current_iteration.real[gid2];
		auto i2 = s.current_iteration.imag[gid2];

		return r1*r1 + i1*i1 > r2*r2 + i2*i2;
	});

	for (int i = 0; i < num_graphs; ++i) {
		unsigned int gid = gids[i];

		if (verbose >= PRINT_DEBUG_LEVEL_3) {
			printf("\ngid:%d, n:", gid);
			for (unsigned int j = s.current_iteration.node_begin[gid]; j < s.current_iteration.node_begin[gid + 1]; ++j)
				printf("%d,", s.current_iteration.node_id_c[j]);

			printf("  ");

			for (unsigned int j = s.current_iteration.sub_node_begin[gid]; j < s.current_iteration.sub_node_begin[gid + 1]; ++j) {
				std::string type;

				auto node_type = s.current_iteration.node_type(gid, j - s.current_iteration.sub_node_begin[gid]);

				if (s.current_iteration.is_trash(gid, j - s.current_iteration.sub_node_begin[gid])) {
					type = "x";
				} else
					switch (node_type) {
						case state_t::left_t:
							type = "l";
							break;

						case state_t::right_t:
							type = "r";
							break;

						case state_t::element_t:
							type = "e";
							break;

						case state_t::pair_t:
							type = "p";
							break;

						default:
							type = "!";
							break;
					}

				printf("%d:(l:%d, r:%d, t:%s), ", j - s.current_iteration.sub_node_begin[gid], s.current_iteration.left_idx__or_element__and_has_most_left_zero__or_is_trash_[j],
					s.current_iteration.right_idx__or_type_[j],
					type.c_str());
			}

			std::cout << "\n";
		}

		PROBA_TYPE real = precision::abs(s.current_iteration.real[gid]) < tolerance ? 0 : s.current_iteration.real[gid];
		PROBA_TYPE imag = precision::abs(s.current_iteration.imag[gid]) < tolerance ? 0 : s.current_iteration.imag[gid];

		std::cout << real << (imag >= 0 ? "+" : "") << imag << "i   ";

		unsigned int num_nodes_ = s.current_iteration.num_nodes(gid);
		for (unsigned short int node = 0; node < num_nodes_; ++node) {
			std::cout << "-|" << (s.current_iteration.left(gid, node) ? "<" : " ") << "|";

			print_node(gid, s.current_iteration.node_id(gid, node), false);

			if (verbose >= PRINT_DEBUG_LEVEL_2)
				std::cout << "|" << s.current_iteration.hash(gid, s.current_iteration.node_id(gid, node));

			std::cout << "|" << (s.current_iteration.right(gid, node) ? ">" : " ") << "|-";
		}

		std::cout << "\n";
	}
}